{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zvPxVt9GcQX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j_WXNHu1fds",
        "outputId": "28b8304a-1e64-47b4-ba25-35d1281ee982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57yDpyYbKfZ5"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Jkju6sniGfUA",
        "outputId": "9103c761-6757-4a10-9e90-10065eb318bd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "7TLN0rWtRfaD",
        "outputId": "48021a2f-fb9e-4983-e007-3b42184a9985"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c318ab635cb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/catdog'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/catdog'"
          ]
        }
      ],
      "source": [
        "os.chdir('/content/drive/MyDrive/catdog')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKUbif_XRjpp"
      },
      "outputs": [],
      "source": [
        "os.listdir('cats')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvXXbWtxHL2A",
        "outputId": "8f1e0d58-5a99-442c-9a5d-636fdbf8f685"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['dogs', 'cats']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV20zNC5JNTZ"
      },
      "outputs": [],
      "source": [
        "img = plt.imread(\"/content/drive/MyDrive/cats/Abyssinian_1.jpg\")\n",
        "res = cv2.resize(img , dsize = (120,120) , interpolation = cv2.INTER_CUBIC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYx-yHTeZLF0"
      },
      "outputs": [],
      "source": [
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYU5DIs_sXQt"
      },
      "outputs": [],
      "source": [
        "res.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jkb3RwOMaZn"
      },
      "outputs": [],
      "source": [
        "res1 = res.flatten()\n",
        "res1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjC6QafLMjIF"
      },
      "outputs": [],
      "source": [
        "img.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "DYYBNN71Kj3B",
        "outputId": "9630b103-4dff-4568-d340-776adaeb2558"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1c4175a850>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udTS7utgLcCq"
      },
      "outputs": [],
      "source": [
        "List1 = []\n",
        "List2 = []\n",
        "c=0\n",
        "for folder in os.listdir():\n",
        "  \n",
        "  for path in os.listdir(folder):\n",
        "    img = plt.imread(folder+ '/' + path)\n",
        "    res = cv2.resize(img , dsize = (50,50) , interpolation = cv2.INTER_CUBIC).flatten()/255\n",
        "    List1.append(res)\n",
        "    List2.append(c)\n",
        "  c=1\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1Bq6t1X9Ruy"
      },
      "outputs": [],
      "source": [
        "List1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHKi1iO46f0y"
      },
      "outputs": [],
      "source": [
        "X = np.array(List1 , dtype = 'float') \n",
        "Y = np.array(List2 , dtype = 'bool')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGLjsK-3O8fk"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJBY9gIjPK1a"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X, Y,test_size = 0.2, random_state = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7kj7IrDPUVs"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiUgWbBXPpoN"
      },
      "outputs": [],
      "source": [
        "reg = linear_model.LogisticRegression(C = 100, penalty = 'l1' , solver = 'saga' , warm_start = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YnGLx-PPq0l",
        "outputId": "58af0024-ee21-4569-9b26-4403c0bb15c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=100, penalty='l1', solver='saga', warm_start=True)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90EVgFHAP0WE"
      },
      "outputs": [],
      "source": [
        "y_predict = reg.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz4yeDKiK0ZV",
        "outputId": "67040613-a554-4a9c-ecdf-8f0b0e5c0d89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.625422582826234"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg.score(x_test , y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSqY0WseIFQ_",
        "outputId": "32a60854-ec58-4ef9-9ec9-3a2b57b404d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.68      0.82      0.74       975\n",
            "        True       0.42      0.25      0.32       504\n",
            "\n",
            "    accuracy                           0.63      1479\n",
            "   macro avg       0.55      0.54      0.53      1479\n",
            "weighted avg       0.59      0.63      0.60      1479\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt9nBlQJMLjK"
      },
      "outputs": [],
      "source": [
        "param_grid = [{'penalty' : ['l1' , 'l2' , 'elasticnet' , 'none'] , 'C' : [1.5 ,  10.0 , 50.0 , 100.0 , 200.0] , 'solver' : ['newton-cg' , 'lbfgs' , 'liblinear' , 'sag' , 'saga'] , 'multi_class' : ['auto' , 'ovr' , 'multinomial'] , 'warm_start' : [True , False] }]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceuou7E0MEUW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "grid_search = GridSearchCV( reg , param_grid , cv =3 , scoring = 'accuracy', return_train_score= True , verbose = 10 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vijMrhISTqDs",
        "outputId": "0deb65aa-316c-4ab5-aa44-cea9e994e0d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 600 candidates, totalling 1800 fits\n",
            "[CV 1/3; 1/600] START C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 1/600] END C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 1/600] START C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 1/600] END C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 1/600] START C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 1/600] END C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 2/600] START C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 2/600] END C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 2/600] START C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 2/600] END C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 2/600] START C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 2/600] END C=1.5, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 3/600] START C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 3/600] END C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 3/600] START C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 3/600] END C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 3/600] START C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 3/600] END C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 4/600] START C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 4/600] END C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 4/600] START C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 4/600] END C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 4/600] START C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 4/600] END C=1.5, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 5/600] START C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 5/600] END C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=0.978, test=0.575) total time=  29.8s\n",
            "[CV 2/3; 5/600] START C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 5/600] END C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=0.978, test=0.583) total time=  29.9s\n",
            "[CV 3/3; 5/600] START C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 5/600] END C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=0.971, test=0.572) total time=  29.3s\n",
            "[CV 1/3; 6/600] START C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 6/600] END C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=0.978, test=0.575) total time=  32.2s\n",
            "[CV 2/3; 6/600] START C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 6/600] END C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=0.978, test=0.583) total time=  29.6s\n",
            "[CV 3/3; 6/600] START C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 6/600] END C=1.5, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=0.971, test=0.572) total time=  28.8s\n",
            "[CV 1/3; 7/600] START C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 7/600] END C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 7/600] START C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 7/600] END C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 7/600] START C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 7/600] END C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 8/600] START C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 8/600] END C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 8/600] START C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 8/600] END C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 8/600] START C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 8/600] END C=1.5, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 9/600] START C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 9/600] END C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.821, test=0.651) total time= 1.0min\n",
            "[CV 2/3; 9/600] START C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 9/600] END C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.818, test=0.642) total time= 1.0min\n",
            "[CV 3/3; 9/600] START C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 9/600] END C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.814, test=0.644) total time= 1.0min\n",
            "[CV 1/3; 10/600] START C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 10/600] END C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.821, test=0.651) total time= 1.0min\n",
            "[CV 2/3; 10/600] START C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 10/600] END C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.818, test=0.642) total time= 1.0min\n",
            "[CV 3/3; 10/600] START C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 10/600] END C=1.5, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.814, test=0.644) total time= 1.0min\n",
            "[CV 1/3; 11/600] START C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 11/600] END C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=0.997, test=0.567) total time=  21.3s\n",
            "[CV 2/3; 11/600] START C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 11/600] END C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=0.997, test=0.587) total time=  21.0s\n",
            "[CV 3/3; 11/600] START C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 11/600] END C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=0.997, test=0.567) total time=  22.2s\n",
            "[CV 1/3; 12/600] START C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 12/600] END C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=0.997, test=0.567) total time=  21.3s\n",
            "[CV 2/3; 12/600] START C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 12/600] END C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=0.997, test=0.587) total time=  20.7s\n",
            "[CV 3/3; 12/600] START C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 12/600] END C=1.5, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=0.997, test=0.567) total time=  22.3s\n",
            "[CV 1/3; 13/600] START C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 13/600] END C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.896, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 13/600] START C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 13/600] END C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.866, test=0.604) total time=   2.6s\n",
            "[CV 3/3; 13/600] START C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 13/600] END C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.861, test=0.595) total time=   2.6s\n",
            "[CV 1/3; 14/600] START C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 14/600] END C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.896, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 14/600] START C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 14/600] END C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.866, test=0.604) total time=   2.5s\n",
            "[CV 3/3; 14/600] START C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 14/600] END C=1.5, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.861, test=0.595) total time=   2.6s\n",
            "[CV 1/3; 15/600] START C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 15/600] END C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=0.997, test=0.567) total time=  57.9s\n",
            "[CV 2/3; 15/600] START C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 15/600] END C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=0.997, test=0.587) total time= 1.1min\n",
            "[CV 3/3; 15/600] START C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 15/600] END C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=0.997, test=0.565) total time=  57.7s\n",
            "[CV 1/3; 16/600] START C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 16/600] END C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=0.997, test=0.567) total time=  50.7s\n",
            "[CV 2/3; 16/600] START C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 16/600] END C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=0.997, test=0.587) total time=  59.2s\n",
            "[CV 3/3; 16/600] START C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 16/600] END C=1.5, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=0.997, test=0.565) total time=  53.2s\n",
            "[CV 1/3; 17/600] START C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 17/600] END C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.881, test=0.626) total time=  22.6s\n",
            "[CV 2/3; 17/600] START C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 17/600] END C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.875, test=0.624) total time=  21.2s\n",
            "[CV 3/3; 17/600] START C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 17/600] END C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.866, test=0.624) total time=  22.2s\n",
            "[CV 1/3; 18/600] START C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 18/600] END C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.881, test=0.626) total time=  22.6s\n",
            "[CV 2/3; 18/600] START C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 18/600] END C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.875, test=0.624) total time=  21.3s\n",
            "[CV 3/3; 18/600] START C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 18/600] END C=1.5, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.866, test=0.624) total time=  21.2s\n",
            "[CV 1/3; 19/600] START C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 19/600] END C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.842, test=0.637) total time=  26.2s\n",
            "[CV 2/3; 19/600] START C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 19/600] END C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.2s\n",
            "[CV 3/3; 19/600] START C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 19/600] END C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.833, test=0.636) total time=  26.1s\n",
            "[CV 1/3; 20/600] START C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 20/600] END C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.842, test=0.637) total time=  27.1s\n",
            "[CV 2/3; 20/600] START C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 20/600] END C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.3s\n",
            "[CV 3/3; 20/600] START C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 20/600] END C=1.5, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.833, test=0.636) total time=  26.2s\n",
            "[CV 1/3; 21/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 21/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 21/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 21/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 21/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 21/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 22/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 22/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 22/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 22/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 22/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 22/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 23/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 23/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 23/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 23/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 23/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 23/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 24/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 24/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 24/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 24/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 24/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 24/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 25/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 25/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 25/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 25/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 25/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 25/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 26/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 26/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 26/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 26/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 26/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 26/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 27/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 27/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 27/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 27/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 27/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 27/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 28/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 28/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 28/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 28/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 28/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 28/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 29/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 29/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 29/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 29/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 29/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 29/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 30/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 30/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 30/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 30/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 30/600] START C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 30/600] END C=1.5, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 31/600] START C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 31/600] END C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.563) total time=  24.2s\n",
            "[CV 2/3; 31/600] START C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 31/600] END C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  23.6s\n",
            "[CV 3/3; 31/600] START C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 31/600] END C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.546) total time=  26.2s\n",
            "[CV 1/3; 32/600] START C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 32/600] END C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.563) total time=  25.0s\n",
            "[CV 2/3; 32/600] START C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 32/600] END C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  23.6s\n",
            "[CV 3/3; 32/600] START C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 32/600] END C=1.5, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.546) total time=  26.6s\n",
            "[CV 1/3; 33/600] START C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 33/600] END C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 33/600] START C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 33/600] END C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.602) total time=   2.6s\n",
            "[CV 3/3; 33/600] START C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 33/600] END C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.874, test=0.590) total time=   2.7s\n",
            "[CV 1/3; 34/600] START C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 34/600] END C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 34/600] START C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 34/600] END C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.602) total time=   2.6s\n",
            "[CV 3/3; 34/600] START C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 34/600] END C=1.5, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 35/600] START C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 35/600] END C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 35/600] START C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 35/600] END C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 35/600] START C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 35/600] END C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 36/600] START C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 36/600] END C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 36/600] START C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 36/600] END C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 36/600] START C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 36/600] END C=1.5, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 37/600] START C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 37/600] END C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.2s\n",
            "[CV 2/3; 37/600] START C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 37/600] END C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.2s\n",
            "[CV 3/3; 37/600] START C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 37/600] END C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.2s\n",
            "[CV 1/3; 38/600] START C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 38/600] END C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  22.1s\n",
            "[CV 2/3; 38/600] START C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 38/600] END C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.3s\n",
            "[CV 3/3; 38/600] START C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 38/600] END C=1.5, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.3s\n",
            "[CV 1/3; 39/600] START C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 39/600] END C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.4s\n",
            "[CV 2/3; 39/600] START C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 39/600] END C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.3s\n",
            "[CV 3/3; 39/600] START C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 39/600] END C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.835, test=0.635) total time=  26.3s\n",
            "[CV 1/3; 40/600] START C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 40/600] END C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  27.1s\n",
            "[CV 2/3; 40/600] START C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 40/600] END C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  27.7s\n",
            "[CV 3/3; 40/600] START C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 40/600] END C=1.5, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.835, test=0.635) total time=  26.3s\n",
            "[CV 1/3; 41/600] START C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 41/600] END C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 41/600] START C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 41/600] END C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 41/600] START C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 41/600] END C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 42/600] START C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 42/600] END C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 42/600] START C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 42/600] END C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 42/600] START C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 42/600] END C=1.5, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 43/600] START C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 43/600] END C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 43/600] START C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 43/600] END C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 43/600] START C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 43/600] END C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 44/600] START C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 44/600] END C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 44/600] START C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 44/600] END C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 44/600] START C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 44/600] END C=1.5, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 45/600] START C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 45/600] END C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=0.978, test=0.575) total time=  39.4s\n",
            "[CV 2/3; 45/600] START C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 45/600] END C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=0.978, test=0.583) total time=  38.9s\n",
            "[CV 3/3; 45/600] START C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 45/600] END C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=0.971, test=0.572) total time=  37.2s\n",
            "[CV 1/3; 46/600] START C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 46/600] END C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=0.978, test=0.575) total time=  38.4s\n",
            "[CV 2/3; 46/600] START C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 46/600] END C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=0.978, test=0.583) total time=  38.5s\n",
            "[CV 3/3; 46/600] START C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 46/600] END C=1.5, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=0.971, test=0.572) total time=  37.6s\n",
            "[CV 1/3; 47/600] START C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 47/600] END C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 47/600] START C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 47/600] END C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 47/600] START C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 47/600] END C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 48/600] START C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 48/600] END C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 48/600] START C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 48/600] END C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 48/600] START C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 48/600] END C=1.5, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 49/600] START C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 49/600] END C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.821, test=0.651) total time= 1.0min\n",
            "[CV 2/3; 49/600] START C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 49/600] END C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.818, test=0.642) total time= 1.0min\n",
            "[CV 3/3; 49/600] START C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 49/600] END C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.814, test=0.644) total time= 1.0min\n",
            "[CV 1/3; 50/600] START C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 50/600] END C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.821, test=0.651) total time= 1.0min\n",
            "[CV 2/3; 50/600] START C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 50/600] END C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.818, test=0.642) total time= 1.0min\n",
            "[CV 3/3; 50/600] START C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 50/600] END C=1.5, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.814, test=0.644) total time= 1.0min\n",
            "[CV 1/3; 51/600] START C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 51/600] END C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=0.997, test=0.567) total time=  19.5s\n",
            "[CV 2/3; 51/600] START C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 51/600] END C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=0.997, test=0.587) total time=  19.2s\n",
            "[CV 3/3; 51/600] START C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 51/600] END C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=0.997, test=0.567) total time=  20.3s\n",
            "[CV 1/3; 52/600] START C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 52/600] END C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=0.997, test=0.567) total time=  19.9s\n",
            "[CV 2/3; 52/600] START C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 52/600] END C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=0.997, test=0.587) total time=  20.4s\n",
            "[CV 3/3; 52/600] START C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 52/600] END C=1.5, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=0.997, test=0.567) total time=  20.8s\n",
            "[CV 1/3; 53/600] START C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 53/600] END C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.896, test=0.604) total time=   2.5s\n",
            "[CV 2/3; 53/600] START C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 53/600] END C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.866, test=0.604) total time=   2.5s\n",
            "[CV 3/3; 53/600] START C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 53/600] END C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.861, test=0.595) total time=   2.5s\n",
            "[CV 1/3; 54/600] START C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 54/600] END C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.896, test=0.604) total time=   2.5s\n",
            "[CV 2/3; 54/600] START C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 54/600] END C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.866, test=0.604) total time=   2.5s\n",
            "[CV 3/3; 54/600] START C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 54/600] END C=1.5, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.861, test=0.595) total time=   2.5s\n",
            "[CV 1/3; 55/600] START C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 55/600] END C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=0.997, test=0.567) total time=  51.0s\n",
            "[CV 2/3; 55/600] START C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 55/600] END C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=0.997, test=0.587) total time= 1.0min\n",
            "[CV 3/3; 55/600] START C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 55/600] END C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=0.997, test=0.565) total time=  53.7s\n",
            "[CV 1/3; 56/600] START C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 56/600] END C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=0.997, test=0.567) total time=  51.5s\n",
            "[CV 2/3; 56/600] START C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 56/600] END C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=0.997, test=0.587) total time= 1.0min\n",
            "[CV 3/3; 56/600] START C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 56/600] END C=1.5, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=0.997, test=0.565) total time=  53.7s\n",
            "[CV 1/3; 57/600] START C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 57/600] END C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.881, test=0.626) total time=  21.1s\n",
            "[CV 2/3; 57/600] START C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 57/600] END C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.875, test=0.624) total time=  21.0s\n",
            "[CV 3/3; 57/600] START C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 57/600] END C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.866, test=0.624) total time=  21.2s\n",
            "[CV 1/3; 58/600] START C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 58/600] END C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.881, test=0.626) total time=  21.9s\n",
            "[CV 2/3; 58/600] START C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 58/600] END C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.875, test=0.624) total time=  21.1s\n",
            "[CV 3/3; 58/600] START C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 58/600] END C=1.5, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.866, test=0.624) total time=  21.1s\n",
            "[CV 1/3; 59/600] START C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 59/600] END C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.842, test=0.637) total time=  26.0s\n",
            "[CV 2/3; 59/600] START C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 59/600] END C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  25.9s\n",
            "[CV 3/3; 59/600] START C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 59/600] END C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.833, test=0.636) total time=  26.1s\n",
            "[CV 1/3; 60/600] START C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 60/600] END C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.842, test=0.637) total time=  26.9s\n",
            "[CV 2/3; 60/600] START C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 60/600] END C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.2s\n",
            "[CV 3/3; 60/600] START C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 60/600] END C=1.5, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.833, test=0.636) total time=  26.0s\n",
            "[CV 1/3; 61/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 61/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 61/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 61/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 61/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 61/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 62/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 62/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 62/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 62/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 62/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 62/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 63/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 63/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 63/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 63/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 63/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 63/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 64/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 64/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 64/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 64/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 64/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 64/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 65/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 65/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 65/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 65/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 65/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 65/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 66/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 66/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 66/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 66/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 66/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 66/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 67/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 67/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 67/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 67/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 67/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 67/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 68/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 68/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 68/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 68/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 68/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 68/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 69/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 69/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 69/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 69/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 69/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 69/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 70/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 70/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 70/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 70/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 70/600] START C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 70/600] END C=1.5, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 71/600] START C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 71/600] END C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.563) total time=  23.9s\n",
            "[CV 2/3; 71/600] START C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 71/600] END C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  23.2s\n",
            "[CV 3/3; 71/600] START C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 71/600] END C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.546) total time=  25.8s\n",
            "[CV 1/3; 72/600] START C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 72/600] END C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.563) total time=  24.6s\n",
            "[CV 2/3; 72/600] START C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 72/600] END C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  23.2s\n",
            "[CV 3/3; 72/600] START C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 72/600] END C=1.5, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.546) total time=  25.6s\n",
            "[CV 1/3; 73/600] START C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 73/600] END C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.604) total time=   2.5s\n",
            "[CV 2/3; 73/600] START C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 73/600] END C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.602) total time=   2.5s\n",
            "[CV 3/3; 73/600] START C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 73/600] END C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.874, test=0.590) total time=   2.5s\n",
            "[CV 1/3; 74/600] START C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 74/600] END C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 74/600] START C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 74/600] END C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.602) total time=   2.5s\n",
            "[CV 3/3; 74/600] START C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 74/600] END C=1.5, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 75/600] START C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 75/600] END C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 75/600] START C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 75/600] END C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 75/600] START C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 75/600] END C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 76/600] START C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 76/600] END C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 76/600] START C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 76/600] END C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 76/600] START C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 76/600] END C=1.5, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 77/600] START C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 77/600] END C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.2s\n",
            "[CV 2/3; 77/600] START C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 77/600] END C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.1s\n",
            "[CV 3/3; 77/600] START C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 77/600] END C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.0s\n",
            "[CV 1/3; 78/600] START C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 78/600] END C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.9s\n",
            "[CV 2/3; 78/600] START C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 78/600] END C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.1s\n",
            "[CV 3/3; 78/600] START C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 78/600] END C=1.5, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.2s\n",
            "[CV 1/3; 79/600] START C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 79/600] END C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.0s\n",
            "[CV 2/3; 79/600] START C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 79/600] END C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.1s\n",
            "[CV 3/3; 79/600] START C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 79/600] END C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.835, test=0.635) total time=  26.0s\n",
            "[CV 1/3; 80/600] START C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 80/600] END C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.7s\n",
            "[CV 2/3; 80/600] START C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 80/600] END C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.0s\n",
            "[CV 3/3; 80/600] START C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 80/600] END C=1.5, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.835, test=0.635) total time=  26.0s\n",
            "[CV 1/3; 81/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 81/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 81/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 81/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 81/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 81/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 82/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 82/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 82/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 82/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 82/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 82/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 83/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 83/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 83/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 83/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 83/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 83/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 84/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 84/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 84/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 84/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 84/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 84/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 85/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 85/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 85/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 85/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 85/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 85/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 86/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 86/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 86/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 86/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 86/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 86/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 87/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 87/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 87/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 87/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 87/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 87/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 88/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 88/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 88/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 88/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 88/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 88/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 89/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 89/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.858, test=0.638) total time= 1.5min\n",
            "[CV 2/3; 89/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 89/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.856, test=0.638) total time= 1.5min\n",
            "[CV 3/3; 89/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 89/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.846, test=0.628) total time= 1.5min\n",
            "[CV 1/3; 90/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 90/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.858, test=0.638) total time= 1.5min\n",
            "[CV 2/3; 90/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 90/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.856, test=0.638) total time= 1.5min\n",
            "[CV 3/3; 90/600] START C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 90/600] END C=1.5, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.846, test=0.628) total time= 1.4min\n",
            "[CV 1/3; 91/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 91/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=0.999, test=0.567) total time= 1.2min\n",
            "[CV 2/3; 91/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 91/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.577) total time=  57.9s\n",
            "[CV 3/3; 91/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 91/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.561) total time= 1.0min\n",
            "[CV 1/3; 92/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 92/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=0.999, test=0.567) total time= 1.2min\n",
            "[CV 2/3; 92/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 92/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.577) total time=  58.2s\n",
            "[CV 3/3; 92/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 92/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.561) total time= 1.1min\n",
            "[CV 1/3; 93/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 93/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.906, test=0.597) total time=  12.1s\n",
            "[CV 2/3; 93/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 93/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.881, test=0.589) total time=  12.6s\n",
            "[CV 3/3; 93/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 93/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.886, test=0.585) total time=  11.8s\n",
            "[CV 1/3; 94/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 94/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.906, test=0.597) total time=  12.3s\n",
            "[CV 2/3; 94/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 94/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.881, test=0.589) total time=  12.7s\n",
            "[CV 3/3; 94/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 94/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.886, test=0.585) total time=  12.0s\n",
            "[CV 1/3; 95/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 95/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 95/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 95/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 95/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 95/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 96/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 96/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 96/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 96/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 96/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 96/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 97/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 97/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.922, test=0.606) total time=  29.1s\n",
            "[CV 2/3; 97/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 97/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.916, test=0.614) total time=  29.7s\n",
            "[CV 3/3; 97/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 97/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.908, test=0.605) total time=  29.2s\n",
            "[CV 1/3; 98/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 98/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.922, test=0.606) total time=  29.2s\n",
            "[CV 2/3; 98/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 98/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.916, test=0.614) total time=  29.2s\n",
            "[CV 3/3; 98/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 98/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.908, test=0.605) total time=  29.1s\n",
            "[CV 1/3; 99/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 99/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.881, test=0.625) total time=  39.1s\n",
            "[CV 2/3; 99/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 99/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.876, test=0.624) total time=  38.2s\n",
            "[CV 3/3; 99/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 99/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.866, test=0.622) total time=  38.6s\n",
            "[CV 1/3; 100/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 100/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.881, test=0.625) total time=  38.4s\n",
            "[CV 2/3; 100/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 100/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.876, test=0.624) total time=  39.2s\n",
            "[CV 3/3; 100/600] START C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 100/600] END C=1.5, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.866, test=0.622) total time=  38.4s\n",
            "[CV 1/3; 101/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 101/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 101/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 101/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 101/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 101/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 102/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 102/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 102/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 102/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 102/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 102/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 103/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 103/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 103/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 103/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 103/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 103/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 104/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 104/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 104/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 104/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 104/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 104/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 105/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 105/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 105/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 105/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 105/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 105/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 106/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 106/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 106/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 106/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 106/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 106/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 107/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 107/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 107/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 107/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 107/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 107/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 108/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 108/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 108/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 108/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 108/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 108/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 109/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 109/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 109/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 109/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 109/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 109/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 110/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 110/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 110/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 110/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 110/600] START C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 110/600] END C=1.5, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 111/600] START C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 111/600] END C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.564) total time= 1.4min\n",
            "[CV 2/3; 111/600] START C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 111/600] END C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.566) total time= 1.2min\n",
            "[CV 3/3; 111/600] START C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 111/600] END C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.548) total time= 1.3min\n",
            "[CV 1/3; 112/600] START C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 112/600] END C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.564) total time= 1.4min\n",
            "[CV 2/3; 112/600] START C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 112/600] END C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.566) total time= 1.2min\n",
            "[CV 3/3; 112/600] START C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 112/600] END C=1.5, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.548) total time= 1.3min\n",
            "[CV 1/3; 113/600] START C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 113/600] END C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.899, test=0.600) total time=  11.5s\n",
            "[CV 2/3; 113/600] START C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 113/600] END C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.888, test=0.592) total time=  12.2s\n",
            "[CV 3/3; 113/600] START C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 113/600] END C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.880, test=0.585) total time=  12.0s\n",
            "[CV 1/3; 114/600] START C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 114/600] END C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.899, test=0.600) total time=  11.8s\n",
            "[CV 2/3; 114/600] START C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 114/600] END C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.888, test=0.592) total time=  12.0s\n",
            "[CV 3/3; 114/600] START C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 114/600] END C=1.5, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.880, test=0.585) total time=  12.1s\n",
            "[CV 1/3; 115/600] START C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 115/600] END C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 115/600] START C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 115/600] END C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 115/600] START C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 115/600] END C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 116/600] START C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 116/600] END C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 116/600] START C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 116/600] END C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 116/600] START C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 116/600] END C=1.5, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 117/600] START C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 117/600] END C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.923, test=0.605) total time=  29.1s\n",
            "[CV 2/3; 117/600] START C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 117/600] END C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.917, test=0.613) total time=  29.2s\n",
            "[CV 3/3; 117/600] START C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 117/600] END C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.909, test=0.604) total time=  30.0s\n",
            "[CV 1/3; 118/600] START C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 118/600] END C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.923, test=0.605) total time=  29.2s\n",
            "[CV 2/3; 118/600] START C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 118/600] END C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.917, test=0.613) total time=  29.1s\n",
            "[CV 3/3; 118/600] START C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 118/600] END C=1.5, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.909, test=0.604) total time=  29.1s\n",
            "[CV 1/3; 119/600] START C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 119/600] END C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.882, test=0.624) total time=  38.2s\n",
            "[CV 2/3; 119/600] START C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 119/600] END C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.877, test=0.625) total time=  38.9s\n",
            "[CV 3/3; 119/600] START C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 119/600] END C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time=  38.2s\n",
            "[CV 1/3; 120/600] START C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 120/600] END C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.882, test=0.624) total time=  38.2s\n",
            "[CV 2/3; 120/600] START C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 120/600] END C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.877, test=0.625) total time=  38.2s\n",
            "[CV 3/3; 120/600] START C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 120/600] END C=1.5, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time=  39.2s\n",
            "[CV 1/3; 121/600] START C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 121/600] END C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 121/600] START C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 121/600] END C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 121/600] START C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 121/600] END C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 122/600] START C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 122/600] END C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 122/600] START C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 122/600] END C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 122/600] START C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 122/600] END C=10.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 123/600] START C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 123/600] END C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 123/600] START C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 123/600] END C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 123/600] START C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 123/600] END C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 124/600] START C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 124/600] END C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 124/600] START C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 124/600] END C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 124/600] START C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 124/600] END C=10.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 125/600] START C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 125/600] END C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.560) total time= 1.4min\n",
            "[CV 2/3; 125/600] START C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 125/600] END C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.562) total time= 1.4min\n",
            "[CV 3/3; 125/600] START C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 125/600] END C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.560) total time= 1.5min\n",
            "[CV 1/3; 126/600] START C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 126/600] END C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.560) total time= 1.4min\n",
            "[CV 2/3; 126/600] START C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 126/600] END C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.562) total time= 1.4min\n",
            "[CV 3/3; 126/600] START C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 126/600] END C=10.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.560) total time= 1.5min\n",
            "[CV 1/3; 127/600] START C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 127/600] END C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 127/600] START C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 127/600] END C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 127/600] START C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 127/600] END C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 128/600] START C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 128/600] END C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 128/600] START C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 128/600] END C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 128/600] START C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 128/600] END C=10.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 129/600] START C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 129/600] END C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.839, test=0.638) total time=  50.1s\n",
            "[CV 2/3; 129/600] START C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 129/600] END C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.839, test=0.636) total time=  49.7s\n",
            "[CV 3/3; 129/600] START C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 129/600] END C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.831, test=0.636) total time=  50.6s\n",
            "[CV 1/3; 130/600] START C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 130/600] END C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.839, test=0.638) total time=  50.0s\n",
            "[CV 2/3; 130/600] START C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 130/600] END C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.839, test=0.636) total time=  49.8s\n",
            "[CV 3/3; 130/600] START C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 130/600] END C=10.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.831, test=0.636) total time=  50.6s\n",
            "[CV 1/3; 131/600] START C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 131/600] END C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.562) total time=  25.5s\n",
            "[CV 2/3; 131/600] START C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 131/600] END C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  24.6s\n",
            "[CV 3/3; 131/600] START C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 131/600] END C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.557) total time=  25.0s\n",
            "[CV 1/3; 132/600] START C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 132/600] END C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.562) total time=  25.7s\n",
            "[CV 2/3; 132/600] START C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 132/600] END C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  24.3s\n",
            "[CV 3/3; 132/600] START C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 132/600] END C=10.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.557) total time=  25.7s\n",
            "[CV 1/3; 133/600] START C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 133/600] END C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.868, test=0.601) total time=   2.5s\n",
            "[CV 2/3; 133/600] START C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 133/600] END C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.870, test=0.599) total time=   2.5s\n",
            "[CV 3/3; 133/600] START C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 133/600] END C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.885, test=0.586) total time=   2.5s\n",
            "[CV 1/3; 134/600] START C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 134/600] END C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.868, test=0.601) total time=   2.5s\n",
            "[CV 2/3; 134/600] START C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 134/600] END C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.870, test=0.599) total time=   2.5s\n",
            "[CV 3/3; 134/600] START C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 134/600] END C=10.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.885, test=0.586) total time=   2.6s\n",
            "[CV 1/3; 135/600] START C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 135/600] END C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.564) total time= 1.0min\n",
            "[CV 2/3; 135/600] START C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 135/600] END C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.567) total time= 1.4min\n",
            "[CV 3/3; 135/600] START C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 135/600] END C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.557) total time= 1.5min\n",
            "[CV 1/3; 136/600] START C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 136/600] END C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.564) total time= 1.0min\n",
            "[CV 2/3; 136/600] START C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 136/600] END C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.567) total time= 1.4min\n",
            "[CV 3/3; 136/600] START C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 136/600] END C=10.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.557) total time= 1.5min\n",
            "[CV 1/3; 137/600] START C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 137/600] END C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.881, test=0.624) total time=  21.1s\n",
            "[CV 2/3; 137/600] START C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 137/600] END C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.1s\n",
            "[CV 3/3; 137/600] START C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 137/600] END C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.1s\n",
            "[CV 1/3; 138/600] START C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 138/600] END C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.881, test=0.624) total time=  21.1s\n",
            "[CV 2/3; 138/600] START C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 138/600] END C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.0s\n",
            "[CV 3/3; 138/600] START C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 138/600] END C=10.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.2s\n",
            "[CV 1/3; 139/600] START C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 139/600] END C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.842, test=0.637) total time=  26.1s\n",
            "[CV 2/3; 139/600] START C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 139/600] END C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.8s\n",
            "[CV 3/3; 139/600] START C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 139/600] END C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.835, test=0.636) total time=  26.1s\n",
            "[CV 1/3; 140/600] START C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 140/600] END C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.842, test=0.637) total time=  26.1s\n",
            "[CV 2/3; 140/600] START C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 140/600] END C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.0s\n",
            "[CV 3/3; 140/600] START C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 140/600] END C=10.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.835, test=0.636) total time=  26.0s\n",
            "[CV 1/3; 141/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 141/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 141/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 141/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 141/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 141/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 142/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 142/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 142/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 142/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 142/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 142/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 143/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 143/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 143/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 143/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 143/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 143/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 144/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 144/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 144/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 144/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 144/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 144/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 145/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 145/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 145/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 145/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 145/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 145/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 146/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 146/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 146/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 146/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 146/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 146/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 147/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 147/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 147/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 147/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 147/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 147/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 148/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 148/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 148/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 148/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 148/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 148/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 149/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 149/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 149/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 149/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 149/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 149/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 150/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 150/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 150/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 150/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 150/600] START C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 150/600] END C=10.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 151/600] START C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 151/600] END C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.563) total time=  23.3s\n",
            "[CV 2/3; 151/600] START C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 151/600] END C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  23.1s\n",
            "[CV 3/3; 151/600] START C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 151/600] END C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.546) total time=  26.3s\n",
            "[CV 1/3; 152/600] START C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 152/600] END C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.563) total time=  23.5s\n",
            "[CV 2/3; 152/600] START C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 152/600] END C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  22.9s\n",
            "[CV 3/3; 152/600] START C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 152/600] END C=10.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.546) total time=  25.5s\n",
            "[CV 1/3; 153/600] START C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 153/600] END C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.604) total time=   2.5s\n",
            "[CV 2/3; 153/600] START C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 153/600] END C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.602) total time=   2.6s\n",
            "[CV 3/3; 153/600] START C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 153/600] END C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.874, test=0.590) total time=   2.5s\n",
            "[CV 1/3; 154/600] START C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 154/600] END C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.604) total time=   2.5s\n",
            "[CV 2/3; 154/600] START C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 154/600] END C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.602) total time=   2.5s\n",
            "[CV 3/3; 154/600] START C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 154/600] END C=10.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.874, test=0.590) total time=   2.5s\n",
            "[CV 1/3; 155/600] START C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 155/600] END C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 155/600] START C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 155/600] END C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 155/600] START C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 155/600] END C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 156/600] START C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 156/600] END C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 156/600] START C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 156/600] END C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 156/600] START C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 156/600] END C=10.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 157/600] START C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 157/600] END C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.1s\n",
            "[CV 2/3; 157/600] START C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 157/600] END C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.1s\n",
            "[CV 3/3; 157/600] START C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 157/600] END C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.1s\n",
            "[CV 1/3; 158/600] START C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 158/600] END C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.8s\n",
            "[CV 2/3; 158/600] START C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 158/600] END C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.3s\n",
            "[CV 3/3; 158/600] START C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 158/600] END C=10.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.1s\n",
            "[CV 1/3; 159/600] START C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 159/600] END C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.0s\n",
            "[CV 2/3; 159/600] START C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 159/600] END C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.1s\n",
            "[CV 3/3; 159/600] START C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 159/600] END C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.835, test=0.635) total time=  26.1s\n",
            "[CV 1/3; 160/600] START C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 160/600] END C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.1s\n",
            "[CV 2/3; 160/600] START C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 160/600] END C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.8s\n",
            "[CV 3/3; 160/600] START C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 160/600] END C=10.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.835, test=0.635) total time=  26.2s\n",
            "[CV 1/3; 161/600] START C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 161/600] END C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 161/600] START C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 161/600] END C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 161/600] START C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 161/600] END C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 162/600] START C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 162/600] END C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 162/600] START C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 162/600] END C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 162/600] START C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 162/600] END C=10.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 163/600] START C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 163/600] END C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 163/600] START C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 163/600] END C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 163/600] START C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 163/600] END C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 164/600] START C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 164/600] END C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 164/600] START C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 164/600] END C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 164/600] START C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 164/600] END C=10.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 165/600] START C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 165/600] END C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.560) total time= 1.4min\n",
            "[CV 2/3; 165/600] START C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 165/600] END C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.562) total time= 1.4min\n",
            "[CV 3/3; 165/600] START C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 165/600] END C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.560) total time= 1.5min\n",
            "[CV 1/3; 166/600] START C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 166/600] END C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.560) total time= 1.4min\n",
            "[CV 2/3; 166/600] START C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 166/600] END C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.562) total time= 1.4min\n",
            "[CV 3/3; 166/600] START C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 166/600] END C=10.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.560) total time= 1.5min\n",
            "[CV 1/3; 167/600] START C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 167/600] END C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 167/600] START C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 167/600] END C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 167/600] START C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 167/600] END C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 168/600] START C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 168/600] END C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 168/600] START C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 168/600] END C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 168/600] START C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 168/600] END C=10.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 169/600] START C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 169/600] END C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.839, test=0.638) total time=  50.9s\n",
            "[CV 2/3; 169/600] START C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 169/600] END C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.839, test=0.636) total time=  49.9s\n",
            "[CV 3/3; 169/600] START C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 169/600] END C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.831, test=0.636) total time=  50.2s\n",
            "[CV 1/3; 170/600] START C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 170/600] END C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.839, test=0.638) total time=  51.1s\n",
            "[CV 2/3; 170/600] START C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 170/600] END C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.839, test=0.636) total time=  50.0s\n",
            "[CV 3/3; 170/600] START C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 170/600] END C=10.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.831, test=0.636) total time=  50.4s\n",
            "[CV 1/3; 171/600] START C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 171/600] END C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.562) total time=  25.6s\n",
            "[CV 2/3; 171/600] START C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 171/600] END C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  24.3s\n",
            "[CV 3/3; 171/600] START C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 171/600] END C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.557) total time=  25.1s\n",
            "[CV 1/3; 172/600] START C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 172/600] END C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.562) total time=  25.8s\n",
            "[CV 2/3; 172/600] START C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 172/600] END C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  24.4s\n",
            "[CV 3/3; 172/600] START C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 172/600] END C=10.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.557) total time=  24.8s\n",
            "[CV 1/3; 173/600] START C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 173/600] END C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.868, test=0.601) total time=   2.5s\n",
            "[CV 2/3; 173/600] START C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 173/600] END C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.870, test=0.599) total time=   2.5s\n",
            "[CV 3/3; 173/600] START C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 173/600] END C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.885, test=0.586) total time=   2.5s\n",
            "[CV 1/3; 174/600] START C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 174/600] END C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.868, test=0.601) total time=   2.4s\n",
            "[CV 2/3; 174/600] START C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 174/600] END C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.870, test=0.599) total time=   2.5s\n",
            "[CV 3/3; 174/600] START C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 174/600] END C=10.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.885, test=0.586) total time=   2.5s\n",
            "[CV 1/3; 175/600] START C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 175/600] END C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.564) total time= 1.0min\n",
            "[CV 2/3; 175/600] START C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 175/600] END C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.567) total time= 1.4min\n",
            "[CV 3/3; 175/600] START C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 175/600] END C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.557) total time= 1.5min\n",
            "[CV 1/3; 176/600] START C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 176/600] END C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.564) total time= 1.0min\n",
            "[CV 2/3; 176/600] START C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 176/600] END C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.567) total time= 1.4min\n",
            "[CV 3/3; 176/600] START C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 176/600] END C=10.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.557) total time= 1.5min\n",
            "[CV 1/3; 177/600] START C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 177/600] END C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.881, test=0.624) total time=  21.2s\n",
            "[CV 2/3; 177/600] START C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 177/600] END C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.2s\n",
            "[CV 3/3; 177/600] START C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 177/600] END C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.1s\n",
            "[CV 1/3; 178/600] START C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 178/600] END C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.881, test=0.624) total time=  21.2s\n",
            "[CV 2/3; 178/600] START C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 178/600] END C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.3s\n",
            "[CV 3/3; 178/600] START C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 178/600] END C=10.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.1s\n",
            "[CV 1/3; 179/600] START C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 179/600] END C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.842, test=0.637) total time=  26.2s\n",
            "[CV 2/3; 179/600] START C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 179/600] END C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.1s\n",
            "[CV 3/3; 179/600] START C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 179/600] END C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.835, test=0.636) total time=  26.9s\n",
            "[CV 1/3; 180/600] START C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 180/600] END C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.842, test=0.637) total time=  26.1s\n",
            "[CV 2/3; 180/600] START C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 180/600] END C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.2s\n",
            "[CV 3/3; 180/600] START C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 180/600] END C=10.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.835, test=0.636) total time=  26.4s\n",
            "[CV 1/3; 181/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 181/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 181/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 181/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 181/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 181/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 182/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 182/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 182/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 182/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 182/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 182/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 183/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 183/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 183/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 183/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 183/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 183/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 184/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 184/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 184/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 184/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 184/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 184/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 185/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 185/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 185/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 185/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 185/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 185/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 186/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 186/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 186/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 186/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 186/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 186/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 187/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 187/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 187/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 187/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 187/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 187/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 188/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 188/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 188/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 188/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 188/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 188/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 189/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 189/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 189/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 189/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 189/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 189/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 190/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 190/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 190/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 190/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 190/600] START C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 190/600] END C=10.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 191/600] START C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 191/600] END C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.563) total time=  23.8s\n",
            "[CV 2/3; 191/600] START C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 191/600] END C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  23.2s\n",
            "[CV 3/3; 191/600] START C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 191/600] END C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.546) total time=  26.1s\n",
            "[CV 1/3; 192/600] START C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 192/600] END C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.563) total time=  24.5s\n",
            "[CV 2/3; 192/600] START C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 192/600] END C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  23.2s\n",
            "[CV 3/3; 192/600] START C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 192/600] END C=10.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.546) total time=  26.1s\n",
            "[CV 1/3; 193/600] START C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 193/600] END C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 193/600] START C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 193/600] END C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.602) total time=   2.6s\n",
            "[CV 3/3; 193/600] START C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 193/600] END C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.874, test=0.590) total time=   2.5s\n",
            "[CV 1/3; 194/600] START C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 194/600] END C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 194/600] START C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 194/600] END C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.602) total time=   2.5s\n",
            "[CV 3/3; 194/600] START C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 194/600] END C=10.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 195/600] START C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 195/600] END C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 195/600] START C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 195/600] END C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 195/600] START C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 195/600] END C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 196/600] START C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 196/600] END C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 196/600] START C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 196/600] END C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 196/600] START C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 196/600] END C=10.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 197/600] START C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 197/600] END C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.2s\n",
            "[CV 2/3; 197/600] START C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 197/600] END C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.2s\n",
            "[CV 3/3; 197/600] START C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 197/600] END C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  23.3s\n",
            "[CV 1/3; 198/600] START C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 198/600] END C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.2s\n",
            "[CV 2/3; 198/600] START C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 198/600] END C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.1s\n",
            "[CV 3/3; 198/600] START C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 198/600] END C=10.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  23.9s\n",
            "[CV 1/3; 199/600] START C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 199/600] END C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.1s\n",
            "[CV 2/3; 199/600] START C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 199/600] END C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.3s\n",
            "[CV 3/3; 199/600] START C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 199/600] END C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.835, test=0.635) total time=  26.3s\n",
            "[CV 1/3; 200/600] START C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 200/600] END C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.2s\n",
            "[CV 2/3; 200/600] START C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 200/600] END C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.3s\n",
            "[CV 3/3; 200/600] START C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 200/600] END C=10.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.835, test=0.635) total time=  26.3s\n",
            "[CV 1/3; 201/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 201/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 201/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 201/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 201/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 201/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 202/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 202/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 202/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 202/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 202/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 202/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 203/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 203/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 203/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 203/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 203/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 203/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 204/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 204/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 204/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 204/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 204/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 204/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 205/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 205/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 205/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 205/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 205/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 205/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 206/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 206/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 206/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 206/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 206/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 206/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 207/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 207/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 207/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 207/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 207/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 207/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 208/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 208/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 208/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 208/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 208/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 208/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 209/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 209/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.879, test=0.628) total time= 1.3min\n",
            "[CV 2/3; 209/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 209/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.874, test=0.624) total time= 1.3min\n",
            "[CV 3/3; 209/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 209/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.864, test=0.625) total time= 1.3min\n",
            "[CV 1/3; 210/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 210/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.879, test=0.628) total time= 1.3min\n",
            "[CV 2/3; 210/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 210/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.874, test=0.624) total time= 1.3min\n",
            "[CV 3/3; 210/600] START C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 210/600] END C=10.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.864, test=0.625) total time= 1.3min\n",
            "[CV 1/3; 211/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 211/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.561) total time= 1.4min\n",
            "[CV 2/3; 211/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 211/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time= 1.2min\n",
            "[CV 3/3; 211/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 211/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.559) total time= 1.3min\n",
            "[CV 1/3; 212/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 212/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.561) total time= 1.4min\n",
            "[CV 2/3; 212/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 212/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time= 1.2min\n",
            "[CV 3/3; 212/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 212/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.559) total time= 1.3min\n",
            "[CV 1/3; 213/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 213/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.901, test=0.598) total time=  11.8s\n",
            "[CV 2/3; 213/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 213/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.595) total time=  12.1s\n",
            "[CV 3/3; 213/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 213/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.888, test=0.583) total time=  12.4s\n",
            "[CV 1/3; 214/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 214/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.901, test=0.598) total time=  11.7s\n",
            "[CV 2/3; 214/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 214/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.595) total time=  12.2s\n",
            "[CV 3/3; 214/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 214/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.888, test=0.583) total time=  12.0s\n",
            "[CV 1/3; 215/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 215/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 215/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 215/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 215/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 215/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 216/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 216/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 216/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 216/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 216/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 216/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 217/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 217/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.923, test=0.605) total time=  29.3s\n",
            "[CV 2/3; 217/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 217/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.917, test=0.613) total time=  29.9s\n",
            "[CV 3/3; 217/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 217/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.909, test=0.605) total time=  29.4s\n",
            "[CV 1/3; 218/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 218/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.923, test=0.605) total time=  29.2s\n",
            "[CV 2/3; 218/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 218/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.917, test=0.613) total time=  29.4s\n",
            "[CV 3/3; 218/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 218/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.909, test=0.605) total time=  29.2s\n",
            "[CV 1/3; 219/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 219/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.882, test=0.624) total time=  38.4s\n",
            "[CV 2/3; 219/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 219/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.877, test=0.625) total time=  39.1s\n",
            "[CV 3/3; 219/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 219/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time=  38.4s\n",
            "[CV 1/3; 220/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 220/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.882, test=0.624) total time=  38.7s\n",
            "[CV 2/3; 220/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 220/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.877, test=0.625) total time=  38.7s\n",
            "[CV 3/3; 220/600] START C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 220/600] END C=10.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time=  38.7s\n",
            "[CV 1/3; 221/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 221/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 221/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 221/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 221/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 221/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 222/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 222/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 222/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 222/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 222/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 222/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 223/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 223/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 223/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 223/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 223/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 223/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 224/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 224/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 224/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 224/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 224/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 224/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 225/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 225/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 225/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 225/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 225/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 225/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 226/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 226/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 226/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 226/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 226/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 226/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 227/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 227/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 227/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 227/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 227/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 227/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 228/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 228/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 228/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 228/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 228/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 228/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 229/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 229/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 229/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 229/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 229/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 229/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 230/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 230/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 230/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 230/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 230/600] START C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 230/600] END C=10.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 231/600] START C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 231/600] END C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.564) total time= 1.4min\n",
            "[CV 2/3; 231/600] START C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 231/600] END C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.566) total time= 1.2min\n",
            "[CV 3/3; 231/600] START C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 231/600] END C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.548) total time= 1.3min\n",
            "[CV 1/3; 232/600] START C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 232/600] END C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.564) total time= 1.4min\n",
            "[CV 2/3; 232/600] START C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 232/600] END C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.566) total time= 1.2min\n",
            "[CV 3/3; 232/600] START C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 232/600] END C=10.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.548) total time= 1.3min\n",
            "[CV 1/3; 233/600] START C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 233/600] END C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.899, test=0.600) total time=  11.7s\n",
            "[CV 2/3; 233/600] START C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 233/600] END C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.888, test=0.592) total time=  12.2s\n",
            "[CV 3/3; 233/600] START C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 233/600] END C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.880, test=0.585) total time=  12.2s\n",
            "[CV 1/3; 234/600] START C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 234/600] END C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.899, test=0.600) total time=  11.9s\n",
            "[CV 2/3; 234/600] START C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 234/600] END C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.888, test=0.592) total time=  12.1s\n",
            "[CV 3/3; 234/600] START C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 234/600] END C=10.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.880, test=0.585) total time=  12.0s\n",
            "[CV 1/3; 235/600] START C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 235/600] END C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 235/600] START C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 235/600] END C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 235/600] START C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 235/600] END C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 236/600] START C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 236/600] END C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 236/600] START C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 236/600] END C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 236/600] START C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 236/600] END C=10.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 237/600] START C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 237/600] END C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.923, test=0.605) total time=  29.2s\n",
            "[CV 2/3; 237/600] START C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 237/600] END C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.917, test=0.613) total time=  29.2s\n",
            "[CV 3/3; 237/600] START C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 237/600] END C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.909, test=0.604) total time=  30.0s\n",
            "[CV 1/3; 238/600] START C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 238/600] END C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.923, test=0.605) total time=  29.3s\n",
            "[CV 2/3; 238/600] START C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 238/600] END C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.917, test=0.613) total time=  29.2s\n",
            "[CV 3/3; 238/600] START C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 238/600] END C=10.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.909, test=0.604) total time=  29.4s\n",
            "[CV 1/3; 239/600] START C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 239/600] END C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.882, test=0.624) total time=  38.4s\n",
            "[CV 2/3; 239/600] START C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 239/600] END C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.877, test=0.625) total time=  38.3s\n",
            "[CV 3/3; 239/600] START C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 239/600] END C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time=  39.1s\n",
            "[CV 1/3; 240/600] START C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 240/600] END C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.882, test=0.624) total time=  38.3s\n",
            "[CV 2/3; 240/600] START C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 240/600] END C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.877, test=0.625) total time=  38.4s\n",
            "[CV 3/3; 240/600] START C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 240/600] END C=10.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time=  38.4s\n",
            "[CV 1/3; 241/600] START C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 241/600] END C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 241/600] START C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 241/600] END C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 241/600] START C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 241/600] END C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 242/600] START C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 242/600] END C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 242/600] START C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 242/600] END C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 242/600] START C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 242/600] END C=50.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 243/600] START C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 243/600] END C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 243/600] START C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 243/600] END C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 243/600] START C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 243/600] END C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 244/600] START C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 244/600] END C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 244/600] START C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 244/600] END C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 244/600] START C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 244/600] END C=50.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 245/600] START C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 245/600] END C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.563) total time= 1.3min\n",
            "[CV 2/3; 245/600] START C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 245/600] END C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.565) total time= 1.3min\n",
            "[CV 3/3; 245/600] START C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 245/600] END C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.558) total time= 1.4min\n",
            "[CV 1/3; 246/600] START C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 246/600] END C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.563) total time= 1.3min\n",
            "[CV 2/3; 246/600] START C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 246/600] END C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.565) total time= 1.3min\n",
            "[CV 3/3; 246/600] START C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 246/600] END C=50.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.558) total time= 1.4min\n",
            "[CV 1/3; 247/600] START C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 247/600] END C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 247/600] START C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 247/600] END C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 247/600] START C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 247/600] END C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 248/600] START C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 248/600] END C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 248/600] START C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 248/600] END C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 248/600] START C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 248/600] END C=50.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 249/600] START C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 249/600] END C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.841, test=0.637) total time=  50.8s\n",
            "[CV 2/3; 249/600] START C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 249/600] END C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.840, test=0.634) total time=  50.5s\n",
            "[CV 3/3; 249/600] START C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 249/600] END C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.834, test=0.636) total time=  51.4s\n",
            "[CV 1/3; 250/600] START C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 250/600] END C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.841, test=0.637) total time=  50.9s\n",
            "[CV 2/3; 250/600] START C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 250/600] END C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.840, test=0.634) total time=  50.3s\n",
            "[CV 3/3; 250/600] START C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 250/600] END C=50.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.834, test=0.636) total time=  50.8s\n",
            "[CV 1/3; 251/600] START C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 251/600] END C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.558) total time=  27.2s\n",
            "[CV 2/3; 251/600] START C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 251/600] END C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.569) total time=  27.1s\n",
            "[CV 3/3; 251/600] START C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 251/600] END C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.556) total time=  27.1s\n",
            "[CV 1/3; 252/600] START C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 252/600] END C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.558) total time=  26.2s\n",
            "[CV 2/3; 252/600] START C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 252/600] END C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.569) total time=  27.0s\n",
            "[CV 3/3; 252/600] START C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 252/600] END C=50.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.556) total time=  27.2s\n",
            "[CV 1/3; 253/600] START C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 253/600] END C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.896, test=0.600) total time=   2.6s\n",
            "[CV 2/3; 253/600] START C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 253/600] END C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.872, test=0.598) total time=   2.6s\n",
            "[CV 3/3; 253/600] START C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 253/600] END C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.890, test=0.585) total time=   2.6s\n",
            "[CV 1/3; 254/600] START C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 254/600] END C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.896, test=0.600) total time=   2.6s\n",
            "[CV 2/3; 254/600] START C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 254/600] END C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.872, test=0.598) total time=   2.6s\n",
            "[CV 3/3; 254/600] START C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 254/600] END C=50.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.890, test=0.585) total time=   2.6s\n",
            "[CV 1/3; 255/600] START C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 255/600] END C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.561) total time= 1.1min\n",
            "[CV 2/3; 255/600] START C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 255/600] END C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.568) total time= 1.2min\n",
            "[CV 3/3; 255/600] START C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 255/600] END C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.555) total time= 1.4min\n",
            "[CV 1/3; 256/600] START C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 256/600] END C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.561) total time= 1.1min\n",
            "[CV 2/3; 256/600] START C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 256/600] END C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.568) total time= 1.2min\n",
            "[CV 3/3; 256/600] START C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 256/600] END C=50.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.555) total time= 1.4min\n",
            "[CV 1/3; 257/600] START C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 257/600] END C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.2s\n",
            "[CV 2/3; 257/600] START C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 257/600] END C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.4s\n",
            "[CV 3/3; 257/600] START C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 257/600] END C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.3s\n",
            "[CV 1/3; 258/600] START C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 258/600] END C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.2s\n",
            "[CV 2/3; 258/600] START C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 258/600] END C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.2s\n",
            "[CV 3/3; 258/600] START C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 258/600] END C=50.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.1s\n",
            "[CV 1/3; 259/600] START C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 259/600] END C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.8s\n",
            "[CV 2/3; 259/600] START C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 259/600] END C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.2s\n",
            "[CV 3/3; 259/600] START C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 259/600] END C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.835, test=0.636) total time=  26.2s\n",
            "[CV 1/3; 260/600] START C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 260/600] END C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.2s\n",
            "[CV 2/3; 260/600] START C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 260/600] END C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.4s\n",
            "[CV 3/3; 260/600] START C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 260/600] END C=50.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.835, test=0.636) total time=  26.6s\n",
            "[CV 1/3; 261/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 261/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 261/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 261/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 261/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 261/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 262/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 262/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 262/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 262/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 262/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 262/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 263/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 263/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 263/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 263/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 263/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 263/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 264/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 264/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 264/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 264/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 264/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 264/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 265/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 265/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 265/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 265/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 265/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 265/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 266/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 266/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 266/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 266/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 266/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 266/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 267/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 267/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 267/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 267/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 267/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 267/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 268/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 268/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 268/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 268/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 268/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 268/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 269/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 269/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 269/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 269/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 269/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 269/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 270/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 270/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 270/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 270/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 270/600] START C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 270/600] END C=50.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 271/600] START C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 271/600] END C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.563) total time=  23.8s\n",
            "[CV 2/3; 271/600] START C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 271/600] END C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  24.0s\n",
            "[CV 3/3; 271/600] START C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 271/600] END C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.546) total time=  25.9s\n",
            "[CV 1/3; 272/600] START C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 272/600] END C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.563) total time=  23.8s\n",
            "[CV 2/3; 272/600] START C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 272/600] END C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  23.2s\n",
            "[CV 3/3; 272/600] START C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 272/600] END C=50.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.546) total time=  25.6s\n",
            "[CV 1/3; 273/600] START C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 273/600] END C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 273/600] START C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 273/600] END C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.602) total time=   2.5s\n",
            "[CV 3/3; 273/600] START C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 273/600] END C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 274/600] START C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 274/600] END C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 274/600] START C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 274/600] END C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.602) total time=   2.6s\n",
            "[CV 3/3; 274/600] START C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 274/600] END C=50.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 275/600] START C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 275/600] END C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 275/600] START C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 275/600] END C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 275/600] START C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 275/600] END C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 276/600] START C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 276/600] END C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 276/600] START C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 276/600] END C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 276/600] START C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 276/600] END C=50.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 277/600] START C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 277/600] END C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.3s\n",
            "[CV 2/3; 277/600] START C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 277/600] END C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.3s\n",
            "[CV 3/3; 277/600] START C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 277/600] END C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.4s\n",
            "[CV 1/3; 278/600] START C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 278/600] END C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  22.1s\n",
            "[CV 2/3; 278/600] START C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 278/600] END C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.4s\n",
            "[CV 3/3; 278/600] START C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 278/600] END C=50.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.3s\n",
            "[CV 1/3; 279/600] START C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 279/600] END C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.2s\n",
            "[CV 2/3; 279/600] START C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 279/600] END C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.1s\n",
            "[CV 3/3; 279/600] START C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 279/600] END C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.835, test=0.635) total time=  26.2s\n",
            "[CV 1/3; 280/600] START C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 280/600] END C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.1s\n",
            "[CV 2/3; 280/600] START C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 280/600] END C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  27.0s\n",
            "[CV 3/3; 280/600] START C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 280/600] END C=50.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.835, test=0.635) total time=  26.2s\n",
            "[CV 1/3; 281/600] START C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 281/600] END C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 281/600] START C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 281/600] END C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 281/600] START C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 281/600] END C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 282/600] START C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 282/600] END C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 282/600] START C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 282/600] END C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 282/600] START C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 282/600] END C=50.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 283/600] START C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 283/600] END C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 283/600] START C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 283/600] END C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 283/600] START C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 283/600] END C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 284/600] START C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 284/600] END C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 284/600] START C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 284/600] END C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 284/600] START C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 284/600] END C=50.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 285/600] START C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 285/600] END C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.563) total time= 1.3min\n",
            "[CV 2/3; 285/600] START C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 285/600] END C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.565) total time= 1.3min\n",
            "[CV 3/3; 285/600] START C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 285/600] END C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.558) total time= 1.4min\n",
            "[CV 1/3; 286/600] START C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 286/600] END C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.563) total time= 1.3min\n",
            "[CV 2/3; 286/600] START C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 286/600] END C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.565) total time= 1.3min\n",
            "[CV 3/3; 286/600] START C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 286/600] END C=50.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.558) total time= 1.4min\n",
            "[CV 1/3; 287/600] START C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 287/600] END C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 287/600] START C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 287/600] END C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 287/600] START C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 287/600] END C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 288/600] START C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 288/600] END C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 288/600] START C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 288/600] END C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 288/600] START C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 288/600] END C=50.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 289/600] START C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 289/600] END C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.841, test=0.637) total time=  58.0s\n",
            "[CV 2/3; 289/600] START C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 289/600] END C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.840, test=0.634) total time=  54.2s\n",
            "[CV 3/3; 289/600] START C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 289/600] END C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.834, test=0.636) total time=  51.6s\n",
            "[CV 1/3; 290/600] START C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 290/600] END C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.841, test=0.637) total time=  52.7s\n",
            "[CV 2/3; 290/600] START C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 290/600] END C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.840, test=0.634) total time=  51.0s\n",
            "[CV 3/3; 290/600] START C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 290/600] END C=50.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.834, test=0.636) total time=  51.2s\n",
            "[CV 1/3; 291/600] START C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 291/600] END C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.558) total time=  26.1s\n",
            "[CV 2/3; 291/600] START C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 291/600] END C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.569) total time=  27.5s\n",
            "[CV 3/3; 291/600] START C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 291/600] END C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.556) total time=  26.9s\n",
            "[CV 1/3; 292/600] START C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 292/600] END C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.558) total time=  26.6s\n",
            "[CV 2/3; 292/600] START C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 292/600] END C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.569) total time=  27.4s\n",
            "[CV 3/3; 292/600] START C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 292/600] END C=50.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.556) total time=  27.5s\n",
            "[CV 1/3; 293/600] START C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 293/600] END C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.896, test=0.600) total time=   2.7s\n",
            "[CV 2/3; 293/600] START C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 293/600] END C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.872, test=0.598) total time=   2.6s\n",
            "[CV 3/3; 293/600] START C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 293/600] END C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.890, test=0.585) total time=   2.6s\n",
            "[CV 1/3; 294/600] START C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 294/600] END C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.896, test=0.600) total time=   2.6s\n",
            "[CV 2/3; 294/600] START C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 294/600] END C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.872, test=0.598) total time=   2.6s\n",
            "[CV 3/3; 294/600] START C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 294/600] END C=50.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.890, test=0.585) total time=   2.7s\n",
            "[CV 1/3; 295/600] START C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 295/600] END C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.561) total time= 1.1min\n",
            "[CV 2/3; 295/600] START C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 295/600] END C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.568) total time= 1.2min\n",
            "[CV 3/3; 295/600] START C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 295/600] END C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.555) total time= 1.4min\n",
            "[CV 1/3; 296/600] START C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 296/600] END C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.561) total time= 1.1min\n",
            "[CV 2/3; 296/600] START C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 296/600] END C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.568) total time= 1.2min\n",
            "[CV 3/3; 296/600] START C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 296/600] END C=50.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.555) total time= 1.5min\n",
            "[CV 1/3; 297/600] START C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 297/600] END C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.5s\n",
            "[CV 2/3; 297/600] START C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 297/600] END C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.6s\n",
            "[CV 3/3; 297/600] START C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 297/600] END C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.5s\n",
            "[CV 1/3; 298/600] START C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 298/600] END C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.6s\n",
            "[CV 2/3; 298/600] START C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 298/600] END C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.6s\n",
            "[CV 3/3; 298/600] START C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 298/600] END C=50.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.7s\n",
            "[CV 1/3; 299/600] START C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 299/600] END C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  27.3s\n",
            "[CV 2/3; 299/600] START C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 299/600] END C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.7s\n",
            "[CV 3/3; 299/600] START C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 299/600] END C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.835, test=0.636) total time=  26.4s\n",
            "[CV 1/3; 300/600] START C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 300/600] END C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.3s\n",
            "[CV 2/3; 300/600] START C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 300/600] END C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.7s\n",
            "[CV 3/3; 300/600] START C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 300/600] END C=50.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.835, test=0.636) total time=  26.7s\n",
            "[CV 1/3; 301/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 301/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 301/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 301/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 301/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 301/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 302/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 302/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 302/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 302/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 302/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 302/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 303/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 303/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 303/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 303/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 303/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 303/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 304/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 304/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 304/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 304/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 304/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 304/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 305/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 305/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 305/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 305/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 305/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 305/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 306/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 306/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 306/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 306/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 306/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 306/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 307/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 307/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 307/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 307/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 307/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 307/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 308/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 308/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 308/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 308/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 308/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 308/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 309/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 309/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 309/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 309/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 309/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 309/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 310/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 310/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 310/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 310/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 310/600] START C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 310/600] END C=50.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 311/600] START C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 311/600] END C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.563) total time=  23.7s\n",
            "[CV 2/3; 311/600] START C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 311/600] END C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  23.8s\n",
            "[CV 3/3; 311/600] START C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 311/600] END C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.546) total time=  25.8s\n",
            "[CV 1/3; 312/600] START C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 312/600] END C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.563) total time=  23.9s\n",
            "[CV 2/3; 312/600] START C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 312/600] END C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  23.5s\n",
            "[CV 3/3; 312/600] START C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 312/600] END C=50.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.546) total time=  26.7s\n",
            "[CV 1/3; 313/600] START C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 313/600] END C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.604) total time=   2.7s\n",
            "[CV 2/3; 313/600] START C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 313/600] END C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.602) total time=   2.7s\n",
            "[CV 3/3; 313/600] START C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 313/600] END C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 314/600] START C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 314/600] END C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.604) total time=   2.7s\n",
            "[CV 2/3; 314/600] START C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 314/600] END C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.602) total time=   2.7s\n",
            "[CV 3/3; 314/600] START C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 314/600] END C=50.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 315/600] START C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 315/600] END C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 315/600] START C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 315/600] END C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 315/600] START C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 315/600] END C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 316/600] START C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 316/600] END C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 316/600] START C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 316/600] END C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 316/600] START C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 316/600] END C=50.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 317/600] START C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 317/600] END C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  26.3s\n",
            "[CV 2/3; 317/600] START C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 317/600] END C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.5s\n",
            "[CV 3/3; 317/600] START C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 317/600] END C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  22.2s\n",
            "[CV 1/3; 318/600] START C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 318/600] END C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  26.5s\n",
            "[CV 2/3; 318/600] START C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 318/600] END C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.9s\n",
            "[CV 3/3; 318/600] START C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 318/600] END C=50.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.4s\n",
            "[CV 1/3; 319/600] START C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 319/600] END C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.4s\n",
            "[CV 2/3; 319/600] START C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 319/600] END C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.2s\n",
            "[CV 3/3; 319/600] START C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 319/600] END C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.835, test=0.635) total time=  26.3s\n",
            "[CV 1/3; 320/600] START C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 320/600] END C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  27.4s\n",
            "[CV 2/3; 320/600] START C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 320/600] END C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.4s\n",
            "[CV 3/3; 320/600] START C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 320/600] END C=50.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.835, test=0.635) total time=  26.5s\n",
            "[CV 1/3; 321/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 321/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 321/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 321/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 321/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 321/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 322/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 322/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 322/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 322/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 322/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 322/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 323/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 323/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 323/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 323/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 323/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 323/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 324/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 324/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 324/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 324/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 324/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 324/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 325/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 325/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 325/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 325/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 325/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 325/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 326/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 326/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 326/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 326/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 326/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 326/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 327/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 327/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 327/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 327/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 327/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 327/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 328/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 328/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 328/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 328/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 328/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 328/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 329/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 329/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.881, test=0.626) total time= 1.3min\n",
            "[CV 2/3; 329/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 329/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.876, test=0.625) total time= 1.3min\n",
            "[CV 3/3; 329/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 329/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.866, test=0.622) total time= 1.3min\n",
            "[CV 1/3; 330/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 330/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.881, test=0.626) total time= 1.3min\n",
            "[CV 2/3; 330/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 330/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.876, test=0.625) total time= 1.3min\n",
            "[CV 3/3; 330/600] START C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 330/600] END C=50.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.866, test=0.622) total time= 1.3min\n",
            "[CV 1/3; 331/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 331/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.558) total time= 1.3min\n",
            "[CV 2/3; 331/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 331/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.569) total time= 1.3min\n",
            "[CV 3/3; 331/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 331/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.554) total time= 1.6min\n",
            "[CV 1/3; 332/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 332/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.558) total time= 1.3min\n",
            "[CV 2/3; 332/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 332/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.569) total time= 1.4min\n",
            "[CV 3/3; 332/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 332/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.554) total time= 1.6min\n",
            "[CV 1/3; 333/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 333/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.896, test=0.600) total time=  12.8s\n",
            "[CV 2/3; 333/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 333/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.887, test=0.601) total time=  12.5s\n",
            "[CV 3/3; 333/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 333/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.880, test=0.585) total time=  13.5s\n",
            "[CV 1/3; 334/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 334/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.896, test=0.600) total time=  12.7s\n",
            "[CV 2/3; 334/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 334/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.887, test=0.601) total time=  13.2s\n",
            "[CV 3/3; 334/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 334/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.880, test=0.585) total time=  13.1s\n",
            "[CV 1/3; 335/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 335/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 335/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 335/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 335/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 335/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 336/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 336/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 336/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 336/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 336/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 336/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 337/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 337/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.923, test=0.605) total time=  30.0s\n",
            "[CV 2/3; 337/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 337/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.917, test=0.613) total time=  29.9s\n",
            "[CV 3/3; 337/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 337/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.909, test=0.604) total time=  30.0s\n",
            "[CV 1/3; 338/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 338/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.923, test=0.605) total time=  29.9s\n",
            "[CV 2/3; 338/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 338/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.917, test=0.613) total time=  29.6s\n",
            "[CV 3/3; 338/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 338/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.909, test=0.604) total time=  30.5s\n",
            "[CV 1/3; 339/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 339/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.882, test=0.624) total time=  39.0s\n",
            "[CV 2/3; 339/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 339/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.877, test=0.625) total time=  39.1s\n",
            "[CV 3/3; 339/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 339/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time=  39.1s\n",
            "[CV 1/3; 340/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 340/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.882, test=0.624) total time=  39.3s\n",
            "[CV 2/3; 340/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 340/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.877, test=0.625) total time=  39.9s\n",
            "[CV 3/3; 340/600] START C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 340/600] END C=50.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time=  38.8s\n",
            "[CV 1/3; 341/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 341/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 341/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 341/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 341/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 341/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 342/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 342/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 342/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 342/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 342/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 342/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 343/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 343/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 343/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 343/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 343/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 343/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 344/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 344/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 344/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 344/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 344/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 344/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 345/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 345/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 345/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 345/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 345/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 345/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 346/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 346/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 346/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 346/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 346/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 346/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 347/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 347/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 347/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 347/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 347/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 347/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 348/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 348/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 348/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 348/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 348/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 348/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 349/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 349/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 349/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 349/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 349/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 349/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 350/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 350/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 350/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 350/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 350/600] START C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 350/600] END C=50.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 351/600] START C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 351/600] END C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.564) total time= 1.4min\n",
            "[CV 2/3; 351/600] START C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 351/600] END C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.566) total time= 1.2min\n",
            "[CV 3/3; 351/600] START C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 351/600] END C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.548) total time= 1.3min\n",
            "[CV 1/3; 352/600] START C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 352/600] END C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.564) total time= 1.4min\n",
            "[CV 2/3; 352/600] START C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 352/600] END C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.566) total time= 1.2min\n",
            "[CV 3/3; 352/600] START C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 352/600] END C=50.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.548) total time= 1.3min\n",
            "[CV 1/3; 353/600] START C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 353/600] END C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.899, test=0.600) total time=  12.1s\n",
            "[CV 2/3; 353/600] START C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 353/600] END C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.888, test=0.592) total time=  12.5s\n",
            "[CV 3/3; 353/600] START C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 353/600] END C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.880, test=0.585) total time=  13.8s\n",
            "[CV 1/3; 354/600] START C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 354/600] END C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.899, test=0.600) total time=  12.4s\n",
            "[CV 2/3; 354/600] START C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 354/600] END C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.888, test=0.592) total time=  12.6s\n",
            "[CV 3/3; 354/600] START C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 354/600] END C=50.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.880, test=0.585) total time=  12.5s\n",
            "[CV 1/3; 355/600] START C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 355/600] END C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 355/600] START C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 355/600] END C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 355/600] START C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 355/600] END C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 356/600] START C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 356/600] END C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 356/600] START C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 356/600] END C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 356/600] START C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 356/600] END C=50.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 357/600] START C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 357/600] END C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.923, test=0.605) total time=  29.4s\n",
            "[CV 2/3; 357/600] START C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 357/600] END C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.917, test=0.613) total time=  29.5s\n",
            "[CV 3/3; 357/600] START C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 357/600] END C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.909, test=0.604) total time=  29.4s\n",
            "[CV 1/3; 358/600] START C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 358/600] END C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.923, test=0.605) total time=  29.6s\n",
            "[CV 2/3; 358/600] START C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 358/600] END C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.917, test=0.613) total time=  30.4s\n",
            "[CV 3/3; 358/600] START C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 358/600] END C=50.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.909, test=0.604) total time=  30.8s\n",
            "[CV 1/3; 359/600] START C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 359/600] END C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.882, test=0.624) total time=  39.4s\n",
            "[CV 2/3; 359/600] START C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 359/600] END C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.877, test=0.625) total time=  38.8s\n",
            "[CV 3/3; 359/600] START C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 359/600] END C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time=  39.2s\n",
            "[CV 1/3; 360/600] START C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 360/600] END C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.882, test=0.624) total time=  39.1s\n",
            "[CV 2/3; 360/600] START C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 360/600] END C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.877, test=0.625) total time=  40.2s\n",
            "[CV 3/3; 360/600] START C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 360/600] END C=50.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time=  40.6s\n",
            "[CV 1/3; 361/600] START C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 361/600] END C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 361/600] START C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 361/600] END C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 361/600] START C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 361/600] END C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 362/600] START C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 362/600] END C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 362/600] START C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 362/600] END C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 362/600] START C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 362/600] END C=100.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 363/600] START C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 363/600] END C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 363/600] START C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 363/600] END C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 363/600] START C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 363/600] END C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 364/600] START C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 364/600] END C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 364/600] START C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 364/600] END C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 364/600] START C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 364/600] END C=100.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 365/600] START C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 365/600] END C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.561) total time= 1.1min\n",
            "[CV 2/3; 365/600] START C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 365/600] END C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.567) total time= 1.2min\n",
            "[CV 3/3; 365/600] START C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 365/600] END C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.556) total time= 1.3min\n",
            "[CV 1/3; 366/600] START C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 366/600] END C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.561) total time= 1.1min\n",
            "[CV 2/3; 366/600] START C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 366/600] END C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.567) total time= 1.2min\n",
            "[CV 3/3; 366/600] START C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 366/600] END C=100.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.556) total time= 1.3min\n",
            "[CV 1/3; 367/600] START C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 367/600] END C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 367/600] START C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 367/600] END C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 367/600] START C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 367/600] END C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 368/600] START C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 368/600] END C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 368/600] START C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 368/600] END C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 368/600] START C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 368/600] END C=100.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 369/600] START C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 369/600] END C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.842, test=0.637) total time=  52.2s\n",
            "[CV 2/3; 369/600] START C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 369/600] END C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.840, test=0.634) total time=  51.9s\n",
            "[CV 3/3; 369/600] START C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 369/600] END C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.834, test=0.636) total time=  51.5s\n",
            "[CV 1/3; 370/600] START C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 370/600] END C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.842, test=0.637) total time=  51.4s\n",
            "[CV 2/3; 370/600] START C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 370/600] END C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.840, test=0.634) total time=  51.5s\n",
            "[CV 3/3; 370/600] START C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 370/600] END C=100.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.834, test=0.636) total time=  51.9s\n",
            "[CV 1/3; 371/600] START C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 371/600] END C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.558) total time=  29.5s\n",
            "[CV 2/3; 371/600] START C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 371/600] END C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.569) total time=  27.0s\n",
            "[CV 3/3; 371/600] START C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 371/600] END C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.554) total time=  27.6s\n",
            "[CV 1/3; 372/600] START C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 372/600] END C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.558) total time=  29.2s\n",
            "[CV 2/3; 372/600] START C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 372/600] END C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.569) total time=  26.5s\n",
            "[CV 3/3; 372/600] START C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 372/600] END C=100.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.554) total time=  28.5s\n",
            "[CV 1/3; 373/600] START C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 373/600] END C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.875, test=0.606) total time=   2.5s\n",
            "[CV 2/3; 373/600] START C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 373/600] END C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.862, test=0.607) total time=   2.6s\n",
            "[CV 3/3; 373/600] START C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 373/600] END C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.864, test=0.599) total time=   2.6s\n",
            "[CV 1/3; 374/600] START C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 374/600] END C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.875, test=0.606) total time=   2.5s\n",
            "[CV 2/3; 374/600] START C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 374/600] END C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.862, test=0.607) total time=   2.6s\n",
            "[CV 3/3; 374/600] START C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 374/600] END C=100.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.864, test=0.599) total time=   2.6s\n",
            "[CV 1/3; 375/600] START C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 375/600] END C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.557) total time= 1.4min\n",
            "[CV 2/3; 375/600] START C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 375/600] END C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.569) total time= 1.8min\n",
            "[CV 3/3; 375/600] START C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 375/600] END C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.556) total time= 1.3min\n",
            "[CV 1/3; 376/600] START C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 376/600] END C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.557) total time= 1.4min\n",
            "[CV 2/3; 376/600] START C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 376/600] END C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.569) total time= 1.8min\n",
            "[CV 3/3; 376/600] START C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 376/600] END C=100.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.556) total time= 1.2min\n",
            "[CV 1/3; 377/600] START C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 377/600] END C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  22.3s\n",
            "[CV 2/3; 377/600] START C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 377/600] END C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.6s\n",
            "[CV 3/3; 377/600] START C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 377/600] END C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.5s\n",
            "[CV 1/3; 378/600] START C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 378/600] END C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.8s\n",
            "[CV 2/3; 378/600] START C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 378/600] END C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.5s\n",
            "[CV 3/3; 378/600] START C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 378/600] END C=100.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.7s\n",
            "[CV 1/3; 379/600] START C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 379/600] END C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  27.0s\n",
            "[CV 2/3; 379/600] START C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 379/600] END C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.6s\n",
            "[CV 3/3; 379/600] START C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 379/600] END C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.835, test=0.636) total time=  27.5s\n",
            "[CV 1/3; 380/600] START C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 380/600] END C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.6s\n",
            "[CV 2/3; 380/600] START C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 380/600] END C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.3s\n",
            "[CV 3/3; 380/600] START C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 380/600] END C=100.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.835, test=0.636) total time=  26.5s\n",
            "[CV 1/3; 381/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 381/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 381/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 381/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 381/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 381/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 382/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 382/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 382/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 382/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 382/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 382/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 383/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 383/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 383/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 383/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 383/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 383/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 384/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 384/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 384/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 384/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 384/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 384/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 385/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 385/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 385/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 385/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 385/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 385/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 386/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 386/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 386/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 386/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 386/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 386/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 387/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 387/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 387/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 387/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 387/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 387/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 388/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 388/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 388/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 388/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 388/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 388/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 389/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 389/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 389/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 389/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 389/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 389/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 390/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 390/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 390/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 390/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 390/600] START C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 390/600] END C=100.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 391/600] START C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 391/600] END C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.563) total time=  24.6s\n",
            "[CV 2/3; 391/600] START C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 391/600] END C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  24.3s\n",
            "[CV 3/3; 391/600] START C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 391/600] END C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.546) total time=  26.4s\n",
            "[CV 1/3; 392/600] START C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 392/600] END C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.563) total time=  25.1s\n",
            "[CV 2/3; 392/600] START C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 392/600] END C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  24.0s\n",
            "[CV 3/3; 392/600] START C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 392/600] END C=100.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.546) total time=  26.3s\n",
            "[CV 1/3; 393/600] START C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 393/600] END C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 393/600] START C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 393/600] END C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.602) total time=   2.6s\n",
            "[CV 3/3; 393/600] START C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 393/600] END C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 394/600] START C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 394/600] END C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 394/600] START C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 394/600] END C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.602) total time=   2.6s\n",
            "[CV 3/3; 394/600] START C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 394/600] END C=100.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 395/600] START C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 395/600] END C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 395/600] START C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 395/600] END C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 395/600] START C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 395/600] END C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 396/600] START C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 396/600] END C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 396/600] START C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 396/600] END C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 396/600] START C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 396/600] END C=100.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 397/600] START C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 397/600] END C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.4s\n",
            "[CV 2/3; 397/600] START C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 397/600] END C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.2s\n",
            "[CV 3/3; 397/600] START C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 397/600] END C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.3s\n",
            "[CV 1/3; 398/600] START C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 398/600] END C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.5s\n",
            "[CV 2/3; 398/600] START C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 398/600] END C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.6s\n",
            "[CV 3/3; 398/600] START C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 398/600] END C=100.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  22.5s\n",
            "[CV 1/3; 399/600] START C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 399/600] END C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.7s\n",
            "[CV 2/3; 399/600] START C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 399/600] END C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  27.9s\n",
            "[CV 3/3; 399/600] START C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 399/600] END C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.835, test=0.635) total time=  27.5s\n",
            "[CV 1/3; 400/600] START C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 400/600] END C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.8s\n",
            "[CV 2/3; 400/600] START C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 400/600] END C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.7s\n",
            "[CV 3/3; 400/600] START C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 400/600] END C=100.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.835, test=0.635) total time=  26.5s\n",
            "[CV 1/3; 401/600] START C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 401/600] END C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 401/600] START C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 401/600] END C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 401/600] START C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 401/600] END C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 402/600] START C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 402/600] END C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 402/600] START C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 402/600] END C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 402/600] START C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 402/600] END C=100.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 403/600] START C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 403/600] END C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 403/600] START C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 403/600] END C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 403/600] START C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 403/600] END C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 404/600] START C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 404/600] END C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 404/600] START C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 404/600] END C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 404/600] START C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 404/600] END C=100.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 405/600] START C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 405/600] END C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.561) total time= 1.1min\n",
            "[CV 2/3; 405/600] START C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 405/600] END C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.567) total time= 1.2min\n",
            "[CV 3/3; 405/600] START C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 405/600] END C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.556) total time= 1.3min\n",
            "[CV 1/3; 406/600] START C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 406/600] END C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.561) total time= 1.1min\n",
            "[CV 2/3; 406/600] START C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 406/600] END C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.567) total time= 1.2min\n",
            "[CV 3/3; 406/600] START C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 406/600] END C=100.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.556) total time= 1.3min\n",
            "[CV 1/3; 407/600] START C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 407/600] END C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 407/600] START C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 407/600] END C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 407/600] START C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 407/600] END C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 408/600] START C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 408/600] END C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 408/600] START C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 408/600] END C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 408/600] START C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 408/600] END C=100.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 409/600] START C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 409/600] END C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.842, test=0.637) total time=  53.0s\n",
            "[CV 2/3; 409/600] START C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 409/600] END C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.840, test=0.634) total time=  51.3s\n",
            "[CV 3/3; 409/600] START C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 409/600] END C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.834, test=0.636) total time=  52.0s\n",
            "[CV 1/3; 410/600] START C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 410/600] END C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.842, test=0.637) total time=  53.4s\n",
            "[CV 2/3; 410/600] START C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 410/600] END C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.840, test=0.634) total time=  51.8s\n",
            "[CV 3/3; 410/600] START C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 410/600] END C=100.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.834, test=0.636) total time=  52.2s\n",
            "[CV 1/3; 411/600] START C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 411/600] END C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.558) total time=  30.4s\n",
            "[CV 2/3; 411/600] START C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 411/600] END C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.569) total time=  28.2s\n",
            "[CV 3/3; 411/600] START C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 411/600] END C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.554) total time=  28.7s\n",
            "[CV 1/3; 412/600] START C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 412/600] END C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.558) total time=  30.2s\n",
            "[CV 2/3; 412/600] START C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 412/600] END C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.569) total time=  27.2s\n",
            "[CV 3/3; 412/600] START C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 412/600] END C=100.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.554) total time=  28.1s\n",
            "[CV 1/3; 413/600] START C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 413/600] END C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.875, test=0.606) total time=   2.6s\n",
            "[CV 2/3; 413/600] START C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 413/600] END C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.862, test=0.607) total time=   2.7s\n",
            "[CV 3/3; 413/600] START C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 413/600] END C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.864, test=0.599) total time=   2.7s\n",
            "[CV 1/3; 414/600] START C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 414/600] END C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.875, test=0.606) total time=   2.6s\n",
            "[CV 2/3; 414/600] START C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 414/600] END C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.862, test=0.607) total time=   2.7s\n",
            "[CV 3/3; 414/600] START C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 414/600] END C=100.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.864, test=0.599) total time=   2.7s\n",
            "[CV 1/3; 415/600] START C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 415/600] END C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.557) total time= 1.3min\n",
            "[CV 2/3; 415/600] START C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 415/600] END C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.569) total time= 1.8min\n",
            "[CV 3/3; 415/600] START C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 415/600] END C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.556) total time= 1.3min\n",
            "[CV 1/3; 416/600] START C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 416/600] END C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.557) total time= 1.4min\n",
            "[CV 2/3; 416/600] START C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 416/600] END C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.569) total time= 1.8min\n",
            "[CV 3/3; 416/600] START C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 416/600] END C=100.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.556) total time= 1.3min\n",
            "[CV 1/3; 417/600] START C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 417/600] END C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.9s\n",
            "[CV 2/3; 417/600] START C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 417/600] END C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  22.9s\n",
            "[CV 3/3; 417/600] START C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 417/600] END C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.9s\n",
            "[CV 1/3; 418/600] START C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 418/600] END C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.8s\n",
            "[CV 2/3; 418/600] START C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 418/600] END C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  23.3s\n",
            "[CV 3/3; 418/600] START C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 418/600] END C=100.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  23.3s\n",
            "[CV 1/3; 419/600] START C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 419/600] END C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  27.5s\n",
            "[CV 2/3; 419/600] START C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 419/600] END C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.7s\n",
            "[CV 3/3; 419/600] START C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 419/600] END C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.835, test=0.636) total time=  26.9s\n",
            "[CV 1/3; 420/600] START C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 420/600] END C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.8s\n",
            "[CV 2/3; 420/600] START C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 420/600] END C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.6s\n",
            "[CV 3/3; 420/600] START C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 420/600] END C=100.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.835, test=0.636) total time=  26.6s\n",
            "[CV 1/3; 421/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 421/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 421/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 421/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 421/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 421/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 422/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 422/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 422/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 422/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 422/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 422/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 423/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 423/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 423/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 423/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 423/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 423/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 424/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 424/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 424/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 424/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 424/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 424/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 425/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 425/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 425/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 425/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 425/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 425/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 426/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 426/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 426/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 426/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 426/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 426/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 427/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 427/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 427/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 427/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 427/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 427/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 428/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 428/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 428/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 428/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 428/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 428/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 429/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 429/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 429/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 429/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 429/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 429/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 430/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 430/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 430/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 430/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 430/600] START C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 430/600] END C=100.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 431/600] START C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 431/600] END C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.563) total time=  24.2s\n",
            "[CV 2/3; 431/600] START C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 431/600] END C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  24.4s\n",
            "[CV 3/3; 431/600] START C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 431/600] END C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.546) total time=  27.3s\n",
            "[CV 1/3; 432/600] START C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 432/600] END C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.563) total time=  24.0s\n",
            "[CV 2/3; 432/600] START C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 432/600] END C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  23.5s\n",
            "[CV 3/3; 432/600] START C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 432/600] END C=100.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.546) total time=  26.3s\n",
            "[CV 1/3; 433/600] START C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 433/600] END C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 433/600] START C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 433/600] END C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.602) total time=   2.7s\n",
            "[CV 3/3; 433/600] START C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 433/600] END C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 434/600] START C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 434/600] END C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.604) total time=   2.7s\n",
            "[CV 2/3; 434/600] START C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 434/600] END C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.602) total time=   2.6s\n",
            "[CV 3/3; 434/600] START C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 434/600] END C=100.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.874, test=0.590) total time=   2.7s\n",
            "[CV 1/3; 435/600] START C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 435/600] END C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 435/600] START C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 435/600] END C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 435/600] START C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 435/600] END C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 436/600] START C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 436/600] END C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 436/600] START C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 436/600] END C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 436/600] START C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 436/600] END C=100.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 437/600] START C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 437/600] END C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  22.2s\n",
            "[CV 2/3; 437/600] START C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 437/600] END C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  22.8s\n",
            "[CV 3/3; 437/600] START C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 437/600] END C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.7s\n",
            "[CV 1/3; 438/600] START C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 438/600] END C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  22.7s\n",
            "[CV 2/3; 438/600] START C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 438/600] END C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.9s\n",
            "[CV 3/3; 438/600] START C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 438/600] END C=100.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.7s\n",
            "[CV 1/3; 439/600] START C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 439/600] END C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.8s\n",
            "[CV 2/3; 439/600] START C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 439/600] END C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.5s\n",
            "[CV 3/3; 439/600] START C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 439/600] END C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.835, test=0.635) total time=  26.7s\n",
            "[CV 1/3; 440/600] START C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 440/600] END C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.6s\n",
            "[CV 2/3; 440/600] START C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 440/600] END C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.5s\n",
            "[CV 3/3; 440/600] START C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 440/600] END C=100.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.835, test=0.635) total time=  27.3s\n",
            "[CV 1/3; 441/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 441/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 441/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 441/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 441/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 441/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 442/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 442/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 442/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 442/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 442/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 442/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 443/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 443/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 443/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 443/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 443/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 443/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 444/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 444/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 444/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 444/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 444/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 444/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 445/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 445/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 445/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 445/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 445/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 445/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 446/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 446/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 446/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 446/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 446/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 446/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 447/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 447/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 447/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 447/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 447/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 447/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 448/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 448/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 448/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 448/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 448/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 448/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 449/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 449/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.881, test=0.624) total time= 1.3min\n",
            "[CV 2/3; 449/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 449/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.876, test=0.625) total time= 1.2min\n",
            "[CV 3/3; 449/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 449/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time= 1.3min\n",
            "[CV 1/3; 450/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 450/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.881, test=0.624) total time= 1.3min\n",
            "[CV 2/3; 450/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 450/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.876, test=0.625) total time= 1.3min\n",
            "[CV 3/3; 450/600] START C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 450/600] END C=100.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time= 1.3min\n",
            "[CV 1/3; 451/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 451/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.558) total time= 1.5min\n",
            "[CV 2/3; 451/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 451/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.568) total time= 1.5min\n",
            "[CV 3/3; 451/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 451/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.554) total time= 1.4min\n",
            "[CV 1/3; 452/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 452/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.558) total time= 1.6min\n",
            "[CV 2/3; 452/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 452/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.568) total time= 1.5min\n",
            "[CV 3/3; 452/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 452/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.554) total time= 1.4min\n",
            "[CV 1/3; 453/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 453/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.897, test=0.594) total time=  12.2s\n",
            "[CV 2/3; 453/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 453/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.896, test=0.590) total time=  12.9s\n",
            "[CV 3/3; 453/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 453/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.882, test=0.590) total time=  12.5s\n",
            "[CV 1/3; 454/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 454/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.897, test=0.594) total time=  12.2s\n",
            "[CV 2/3; 454/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 454/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.896, test=0.590) total time=  12.7s\n",
            "[CV 3/3; 454/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 454/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.882, test=0.590) total time=  13.0s\n",
            "[CV 1/3; 455/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 455/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 455/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 455/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 455/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 455/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 456/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 456/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 456/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 456/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 456/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 456/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 457/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 457/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.923, test=0.605) total time=  29.3s\n",
            "[CV 2/3; 457/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 457/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.917, test=0.613) total time=  29.3s\n",
            "[CV 3/3; 457/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 457/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.909, test=0.604) total time=  29.5s\n",
            "[CV 1/3; 458/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 458/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.923, test=0.605) total time=  30.7s\n",
            "[CV 2/3; 458/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 458/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.917, test=0.613) total time=  29.8s\n",
            "[CV 3/3; 458/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 458/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.909, test=0.604) total time=  30.3s\n",
            "[CV 1/3; 459/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 459/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.882, test=0.624) total time=  40.3s\n",
            "[CV 2/3; 459/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 459/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.877, test=0.625) total time=  40.1s\n",
            "[CV 3/3; 459/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 459/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time=  39.4s\n",
            "[CV 1/3; 460/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 460/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.882, test=0.624) total time=  39.9s\n",
            "[CV 2/3; 460/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 460/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.877, test=0.625) total time=  39.2s\n",
            "[CV 3/3; 460/600] START C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 460/600] END C=100.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time=  39.3s\n",
            "[CV 1/3; 461/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 461/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 461/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 461/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 461/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 461/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 462/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 462/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 462/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 462/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 462/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 462/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 463/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 463/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 463/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 463/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 463/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 463/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 464/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 464/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 464/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 464/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 464/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 464/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 465/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 465/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 465/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 465/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 465/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 465/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 466/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 466/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 466/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 466/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 466/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 466/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 467/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 467/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 467/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 467/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 467/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 467/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 468/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 468/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 468/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 468/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 468/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 468/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 469/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 469/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 469/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 469/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 469/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 469/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 470/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 470/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 470/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 470/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 470/600] START C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 470/600] END C=100.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 471/600] START C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 471/600] END C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.564) total time= 1.4min\n",
            "[CV 2/3; 471/600] START C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 471/600] END C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.566) total time= 1.2min\n",
            "[CV 3/3; 471/600] START C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 471/600] END C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.548) total time= 1.3min\n",
            "[CV 1/3; 472/600] START C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 472/600] END C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.564) total time= 1.5min\n",
            "[CV 2/3; 472/600] START C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 472/600] END C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.566) total time= 1.2min\n",
            "[CV 3/3; 472/600] START C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 472/600] END C=100.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.548) total time= 1.3min\n",
            "[CV 1/3; 473/600] START C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 473/600] END C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.899, test=0.600) total time=  12.2s\n",
            "[CV 2/3; 473/600] START C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 473/600] END C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.888, test=0.592) total time=  14.1s\n",
            "[CV 3/3; 473/600] START C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 473/600] END C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.880, test=0.585) total time=  12.7s\n",
            "[CV 1/3; 474/600] START C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 474/600] END C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.899, test=0.600) total time=  12.2s\n",
            "[CV 2/3; 474/600] START C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 474/600] END C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.888, test=0.592) total time=  12.8s\n",
            "[CV 3/3; 474/600] START C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 474/600] END C=100.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.880, test=0.585) total time=  12.5s\n",
            "[CV 1/3; 475/600] START C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 475/600] END C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 475/600] START C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 475/600] END C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 475/600] START C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 475/600] END C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 476/600] START C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 476/600] END C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 476/600] START C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 476/600] END C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 476/600] START C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 476/600] END C=100.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 477/600] START C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 477/600] END C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.923, test=0.605) total time=  29.8s\n",
            "[CV 2/3; 477/600] START C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 477/600] END C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.917, test=0.613) total time=  29.6s\n",
            "[CV 3/3; 477/600] START C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 477/600] END C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.909, test=0.604) total time=  29.7s\n",
            "[CV 1/3; 478/600] START C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 478/600] END C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.923, test=0.605) total time=  30.7s\n",
            "[CV 2/3; 478/600] START C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 478/600] END C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.917, test=0.613) total time=  33.0s\n",
            "[CV 3/3; 478/600] START C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 478/600] END C=100.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.909, test=0.604) total time=  30.7s\n",
            "[CV 1/3; 479/600] START C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 479/600] END C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.882, test=0.624) total time=  40.5s\n",
            "[CV 2/3; 479/600] START C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 479/600] END C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.877, test=0.625) total time=  39.2s\n",
            "[CV 3/3; 479/600] START C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 479/600] END C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time=  39.6s\n",
            "[CV 1/3; 480/600] START C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 480/600] END C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.882, test=0.624) total time=  39.4s\n",
            "[CV 2/3; 480/600] START C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 480/600] END C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.877, test=0.625) total time=  39.8s\n",
            "[CV 3/3; 480/600] START C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 480/600] END C=100.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time=  38.9s\n",
            "[CV 1/3; 481/600] START C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 481/600] END C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 481/600] START C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 481/600] END C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 481/600] START C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 481/600] END C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 482/600] START C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 482/600] END C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 482/600] START C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 482/600] END C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 482/600] START C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 482/600] END C=200.0, multi_class=auto, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 483/600] START C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 483/600] END C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 483/600] START C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 483/600] END C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 483/600] START C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 483/600] END C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 484/600] START C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 484/600] END C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 484/600] START C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 484/600] END C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 484/600] START C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 484/600] END C=200.0, multi_class=auto, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 485/600] START C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 485/600] END C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.562) total time= 1.0min\n",
            "[CV 2/3; 485/600] START C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 485/600] END C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.565) total time= 1.1min\n",
            "[CV 3/3; 485/600] START C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 485/600] END C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.553) total time= 1.2min\n",
            "[CV 1/3; 486/600] START C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 486/600] END C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.562) total time= 1.0min\n",
            "[CV 2/3; 486/600] START C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 486/600] END C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.565) total time= 1.1min\n",
            "[CV 3/3; 486/600] START C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 486/600] END C=200.0, multi_class=auto, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.553) total time= 1.2min\n",
            "[CV 1/3; 487/600] START C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 487/600] END C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 487/600] START C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 487/600] END C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 487/600] START C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 487/600] END C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 488/600] START C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 488/600] END C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 488/600] START C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 488/600] END C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 488/600] START C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 488/600] END C=200.0, multi_class=auto, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 489/600] START C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 489/600] END C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.842, test=0.637) total time=  52.5s\n",
            "[CV 2/3; 489/600] START C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 489/600] END C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  52.4s\n",
            "[CV 3/3; 489/600] START C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 489/600] END C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=True;, score=(train=0.835, test=0.636) total time=  52.4s\n",
            "[CV 1/3; 490/600] START C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 490/600] END C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.842, test=0.637) total time=  54.2s\n",
            "[CV 2/3; 490/600] START C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 490/600] END C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  52.8s\n",
            "[CV 3/3; 490/600] START C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 490/600] END C=200.0, multi_class=auto, penalty=l1, solver=saga, warm_start=False;, score=(train=0.835, test=0.636) total time=  52.4s\n",
            "[CV 1/3; 491/600] START C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 491/600] END C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.558) total time=  30.4s\n",
            "[CV 2/3; 491/600] START C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 491/600] END C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.568) total time=  29.4s\n",
            "[CV 3/3; 491/600] START C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 491/600] END C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.554) total time=  28.9s\n",
            "[CV 1/3; 492/600] START C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 492/600] END C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.558) total time=  31.8s\n",
            "[CV 2/3; 492/600] START C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 492/600] END C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.568) total time=  29.8s\n",
            "[CV 3/3; 492/600] START C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 492/600] END C=200.0, multi_class=auto, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.554) total time=  29.0s\n",
            "[CV 1/3; 493/600] START C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 493/600] END C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.871, test=0.606) total time=   2.6s\n",
            "[CV 2/3; 493/600] START C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 493/600] END C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.610) total time=   2.5s\n",
            "[CV 3/3; 493/600] START C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 493/600] END C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.869, test=0.591) total time=   2.6s\n",
            "[CV 1/3; 494/600] START C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 494/600] END C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.871, test=0.606) total time=   2.6s\n",
            "[CV 2/3; 494/600] START C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 494/600] END C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.610) total time=   2.6s\n",
            "[CV 3/3; 494/600] START C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 494/600] END C=200.0, multi_class=auto, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.869, test=0.591) total time=   2.6s\n",
            "[CV 1/3; 495/600] START C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 495/600] END C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.559) total time= 1.1min\n",
            "[CV 2/3; 495/600] START C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 495/600] END C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.570) total time= 1.6min\n",
            "[CV 3/3; 495/600] START C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 495/600] END C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.552) total time= 1.5min\n",
            "[CV 1/3; 496/600] START C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 496/600] END C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.559) total time= 1.2min\n",
            "[CV 2/3; 496/600] START C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 496/600] END C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.570) total time= 1.6min\n",
            "[CV 3/3; 496/600] START C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 496/600] END C=200.0, multi_class=auto, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.552) total time= 1.6min\n",
            "[CV 1/3; 497/600] START C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 497/600] END C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.6s\n",
            "[CV 2/3; 497/600] START C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 497/600] END C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.5s\n",
            "[CV 3/3; 497/600] START C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 497/600] END C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.8s\n",
            "[CV 1/3; 498/600] START C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 498/600] END C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  22.5s\n",
            "[CV 2/3; 498/600] START C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 498/600] END C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  22.1s\n",
            "[CV 3/3; 498/600] START C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 498/600] END C=200.0, multi_class=auto, penalty=l2, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  23.9s\n",
            "[CV 1/3; 499/600] START C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 499/600] END C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  27.4s\n",
            "[CV 2/3; 499/600] START C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 499/600] END C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.4s\n",
            "[CV 3/3; 499/600] START C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 499/600] END C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=True;, score=(train=0.835, test=0.636) total time=  26.7s\n",
            "[CV 1/3; 500/600] START C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 500/600] END C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.7s\n",
            "[CV 2/3; 500/600] START C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 500/600] END C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.5s\n",
            "[CV 3/3; 500/600] START C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 500/600] END C=200.0, multi_class=auto, penalty=l2, solver=saga, warm_start=False;, score=(train=0.835, test=0.636) total time=  26.6s\n",
            "[CV 1/3; 501/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 501/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 501/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 501/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 501/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 501/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 502/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 502/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 502/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 502/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 502/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 502/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 503/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 503/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 503/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 503/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 503/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 503/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 504/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 504/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 504/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 504/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 504/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 504/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 505/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 505/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 505/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 505/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 505/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 505/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 506/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 506/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 506/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 506/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 506/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 506/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 507/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 507/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 507/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 507/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 507/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 507/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 508/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 508/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 508/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 508/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 508/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 508/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 509/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 509/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 509/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 509/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 509/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 509/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 510/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 510/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 510/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 510/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 510/600] START C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 510/600] END C=200.0, multi_class=auto, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 511/600] START C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 511/600] END C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.563) total time=  25.4s\n",
            "[CV 2/3; 511/600] START C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 511/600] END C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  23.4s\n",
            "[CV 3/3; 511/600] START C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 511/600] END C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.546) total time=  26.7s\n",
            "[CV 1/3; 512/600] START C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 512/600] END C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.563) total time=  24.8s\n",
            "[CV 2/3; 512/600] START C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 512/600] END C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  23.9s\n",
            "[CV 3/3; 512/600] START C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 512/600] END C=200.0, multi_class=auto, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.546) total time=  26.4s\n",
            "[CV 1/3; 513/600] START C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 513/600] END C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.604) total time=   2.7s\n",
            "[CV 2/3; 513/600] START C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 513/600] END C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.602) total time=   2.7s\n",
            "[CV 3/3; 513/600] START C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 513/600] END C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 514/600] START C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 514/600] END C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 514/600] START C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 514/600] END C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.602) total time=   2.7s\n",
            "[CV 3/3; 514/600] START C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 514/600] END C=200.0, multi_class=auto, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.874, test=0.590) total time=   2.8s\n",
            "[CV 1/3; 515/600] START C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 515/600] END C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 515/600] START C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 515/600] END C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 515/600] START C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 515/600] END C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 516/600] START C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 516/600] END C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 516/600] START C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 516/600] END C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 516/600] START C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 516/600] END C=200.0, multi_class=auto, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 517/600] START C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 517/600] END C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  22.1s\n",
            "[CV 2/3; 517/600] START C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 517/600] END C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  22.3s\n",
            "[CV 3/3; 517/600] START C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 517/600] END C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.6s\n",
            "[CV 1/3; 518/600] START C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 518/600] END C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.7s\n",
            "[CV 2/3; 518/600] START C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 518/600] END C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.7s\n",
            "[CV 3/3; 518/600] START C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 518/600] END C=200.0, multi_class=auto, penalty=none, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.6s\n",
            "[CV 1/3; 519/600] START C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 519/600] END C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.7s\n",
            "[CV 2/3; 519/600] START C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 519/600] END C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.3s\n",
            "[CV 3/3; 519/600] START C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 519/600] END C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=True;, score=(train=0.835, test=0.635) total time=  27.6s\n",
            "[CV 1/3; 520/600] START C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 520/600] END C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.9s\n",
            "[CV 2/3; 520/600] START C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 520/600] END C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.9s\n",
            "[CV 3/3; 520/600] START C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 520/600] END C=200.0, multi_class=auto, penalty=none, solver=saga, warm_start=False;, score=(train=0.835, test=0.635) total time=  26.4s\n",
            "[CV 1/3; 521/600] START C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 521/600] END C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 521/600] START C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 521/600] END C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 521/600] START C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 521/600] END C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 522/600] START C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 522/600] END C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 522/600] START C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 522/600] END C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 522/600] START C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 522/600] END C=200.0, multi_class=ovr, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 523/600] START C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 523/600] END C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 523/600] START C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 523/600] END C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 523/600] START C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 523/600] END C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 524/600] START C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 524/600] END C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 524/600] START C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 524/600] END C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 524/600] START C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 524/600] END C=200.0, multi_class=ovr, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 525/600] START C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 525/600] END C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.562) total time= 1.0min\n",
            "[CV 2/3; 525/600] START C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 525/600] END C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.565) total time= 1.2min\n",
            "[CV 3/3; 525/600] START C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 525/600] END C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.553) total time= 1.2min\n",
            "[CV 1/3; 526/600] START C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 526/600] END C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.562) total time= 1.0min\n",
            "[CV 2/3; 526/600] START C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 526/600] END C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.565) total time= 1.1min\n",
            "[CV 3/3; 526/600] START C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 526/600] END C=200.0, multi_class=ovr, penalty=l1, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.553) total time= 1.2min\n",
            "[CV 1/3; 527/600] START C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 527/600] END C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 527/600] START C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 527/600] END C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 527/600] START C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 527/600] END C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 528/600] START C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 528/600] END C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 528/600] START C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 528/600] END C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 528/600] START C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 528/600] END C=200.0, multi_class=ovr, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 529/600] START C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 529/600] END C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.842, test=0.637) total time=  52.3s\n",
            "[CV 2/3; 529/600] START C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 529/600] END C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  51.3s\n",
            "[CV 3/3; 529/600] START C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 529/600] END C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=True;, score=(train=0.835, test=0.636) total time=  51.4s\n",
            "[CV 1/3; 530/600] START C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 530/600] END C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.842, test=0.637) total time=  51.9s\n",
            "[CV 2/3; 530/600] START C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 530/600] END C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  52.0s\n",
            "[CV 3/3; 530/600] START C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 530/600] END C=200.0, multi_class=ovr, penalty=l1, solver=saga, warm_start=False;, score=(train=0.835, test=0.636) total time=  52.1s\n",
            "[CV 1/3; 531/600] START C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 531/600] END C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.558) total time=  30.4s\n",
            "[CV 2/3; 531/600] START C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 531/600] END C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.568) total time=  29.1s\n",
            "[CV 3/3; 531/600] START C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 531/600] END C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.554) total time=  29.6s\n",
            "[CV 1/3; 532/600] START C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 532/600] END C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.558) total time=  30.3s\n",
            "[CV 2/3; 532/600] START C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 532/600] END C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.568) total time=  29.4s\n",
            "[CV 3/3; 532/600] START C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 532/600] END C=200.0, multi_class=ovr, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.554) total time=  28.7s\n",
            "[CV 1/3; 533/600] START C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 533/600] END C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.871, test=0.606) total time=   2.6s\n",
            "[CV 2/3; 533/600] START C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 533/600] END C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.610) total time=   2.6s\n",
            "[CV 3/3; 533/600] START C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 533/600] END C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.869, test=0.591) total time=   2.7s\n",
            "[CV 1/3; 534/600] START C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 534/600] END C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.871, test=0.606) total time=   2.6s\n",
            "[CV 2/3; 534/600] START C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 534/600] END C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.610) total time=   2.6s\n",
            "[CV 3/3; 534/600] START C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 534/600] END C=200.0, multi_class=ovr, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.869, test=0.591) total time=   2.7s\n",
            "[CV 1/3; 535/600] START C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 535/600] END C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.559) total time= 1.2min\n",
            "[CV 2/3; 535/600] START C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 535/600] END C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.570) total time= 1.6min\n",
            "[CV 3/3; 535/600] START C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 535/600] END C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=True;, score=(train=1.000, test=0.552) total time= 1.6min\n",
            "[CV 1/3; 536/600] START C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 536/600] END C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.559) total time= 1.2min\n",
            "[CV 2/3; 536/600] START C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 536/600] END C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.570) total time= 1.6min\n",
            "[CV 3/3; 536/600] START C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 536/600] END C=200.0, multi_class=ovr, penalty=l2, solver=liblinear, warm_start=False;, score=(train=1.000, test=0.552) total time= 1.5min\n",
            "[CV 1/3; 537/600] START C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 537/600] END C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.4s\n",
            "[CV 2/3; 537/600] START C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 537/600] END C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.5s\n",
            "[CV 3/3; 537/600] START C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 537/600] END C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.5s\n",
            "[CV 1/3; 538/600] START C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 538/600] END C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.5s\n",
            "[CV 2/3; 538/600] START C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 538/600] END C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  22.4s\n",
            "[CV 3/3; 538/600] START C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 538/600] END C=200.0, multi_class=ovr, penalty=l2, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.7s\n",
            "[CV 1/3; 539/600] START C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 539/600] END C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  26.4s\n",
            "[CV 2/3; 539/600] START C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 539/600] END C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  26.3s\n",
            "[CV 3/3; 539/600] START C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 539/600] END C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=True;, score=(train=0.835, test=0.636) total time=  26.6s\n",
            "[CV 1/3; 540/600] START C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 540/600] END C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.4s\n",
            "[CV 2/3; 540/600] START C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 540/600] END C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.6s\n",
            "[CV 3/3; 540/600] START C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 540/600] END C=200.0, multi_class=ovr, penalty=l2, solver=saga, warm_start=False;, score=(train=0.835, test=0.636) total time=  27.4s\n",
            "[CV 1/3; 541/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 541/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 541/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 541/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 541/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 541/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 542/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 542/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 542/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 542/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 542/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 542/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 543/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 543/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 543/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 543/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 543/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 543/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 544/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 544/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 544/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 544/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 544/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 544/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 545/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 545/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 545/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 545/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 545/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 545/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 546/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 546/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 546/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 546/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 546/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 546/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 547/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 547/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 547/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 547/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 547/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 547/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 548/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 548/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 548/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 548/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 548/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 548/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 549/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 549/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 549/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 549/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 549/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 549/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 550/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 550/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 550/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 550/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 550/600] START C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 550/600] END C=200.0, multi_class=ovr, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 551/600] START C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 551/600] END C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.563) total time=  24.0s\n",
            "[CV 2/3; 551/600] START C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 551/600] END C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time=  23.6s\n",
            "[CV 3/3; 551/600] START C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 551/600] END C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.546) total time=  26.2s\n",
            "[CV 1/3; 552/600] START C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 552/600] END C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.563) total time=  24.0s\n",
            "[CV 2/3; 552/600] START C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 552/600] END C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time=  23.0s\n",
            "[CV 3/3; 552/600] START C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 552/600] END C=200.0, multi_class=ovr, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.546) total time=  26.0s\n",
            "[CV 1/3; 553/600] START C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 553/600] END C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 553/600] START C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 553/600] END C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.860, test=0.602) total time=   2.6s\n",
            "[CV 3/3; 553/600] START C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 553/600] END C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.874, test=0.590) total time=   2.6s\n",
            "[CV 1/3; 554/600] START C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 554/600] END C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.604) total time=   2.6s\n",
            "[CV 2/3; 554/600] START C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 554/600] END C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.860, test=0.602) total time=   2.6s\n",
            "[CV 3/3; 554/600] START C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 554/600] END C=200.0, multi_class=ovr, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.874, test=0.590) total time=   3.4s\n",
            "[CV 1/3; 555/600] START C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 555/600] END C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 555/600] START C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 555/600] END C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 555/600] START C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 555/600] END C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 556/600] START C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 556/600] END C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 556/600] START C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 556/600] END C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 556/600] START C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 556/600] END C=200.0, multi_class=ovr, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 557/600] START C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 557/600] END C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.882, test=0.624) total time=  21.6s\n",
            "[CV 2/3; 557/600] START C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 557/600] END C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.876, test=0.623) total time=  21.4s\n",
            "[CV 3/3; 557/600] START C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 557/600] END C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=True;, score=(train=0.867, test=0.622) total time=  21.5s\n",
            "[CV 1/3; 558/600] START C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 558/600] END C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.882, test=0.624) total time=  21.4s\n",
            "[CV 2/3; 558/600] START C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 558/600] END C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.876, test=0.623) total time=  21.4s\n",
            "[CV 3/3; 558/600] START C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 558/600] END C=200.0, multi_class=ovr, penalty=none, solver=sag, warm_start=False;, score=(train=0.867, test=0.622) total time=  21.5s\n",
            "[CV 1/3; 559/600] START C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 559/600] END C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.842, test=0.638) total time=  27.1s\n",
            "[CV 2/3; 559/600] START C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 559/600] END C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.840, test=0.635) total time=  27.3s\n",
            "[CV 3/3; 559/600] START C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 559/600] END C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=True;, score=(train=0.835, test=0.635) total time=  26.6s\n",
            "[CV 1/3; 560/600] START C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 560/600] END C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.842, test=0.638) total time=  26.7s\n",
            "[CV 2/3; 560/600] START C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 560/600] END C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.840, test=0.635) total time=  26.3s\n",
            "[CV 3/3; 560/600] START C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 560/600] END C=200.0, multi_class=ovr, penalty=none, solver=saga, warm_start=False;, score=(train=0.835, test=0.635) total time=  27.0s\n",
            "[CV 1/3; 561/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 561/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 561/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 561/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 561/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 561/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 562/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 562/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 562/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 562/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 562/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 562/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 563/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 563/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 563/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 563/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 563/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 563/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 564/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 564/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 564/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 564/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 564/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 564/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 565/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 565/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 565/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 565/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 565/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 565/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 566/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 566/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 566/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 566/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 566/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 566/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 567/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 1/3; 567/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 567/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 2/3; 567/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 567/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True\n",
            "[CV 3/3; 567/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 568/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 1/3; 568/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 568/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 2/3; 568/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 568/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False\n",
            "[CV 3/3; 568/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 569/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 569/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.882, test=0.624) total time= 1.3min\n",
            "[CV 2/3; 569/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 569/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.877, test=0.625) total time= 1.2min\n",
            "[CV 3/3; 569/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 569/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time= 1.2min\n",
            "[CV 1/3; 570/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 570/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.882, test=0.624) total time= 1.3min\n",
            "[CV 2/3; 570/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 570/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.877, test=0.625) total time= 1.2min\n",
            "[CV 3/3; 570/600] START C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 570/600] END C=200.0, multi_class=multinomial, penalty=l1, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time= 1.3min\n",
            "[CV 1/3; 571/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 571/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.559) total time= 1.5min\n",
            "[CV 2/3; 571/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 571/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.567) total time= 1.4min\n",
            "[CV 3/3; 571/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 571/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.553) total time= 1.5min\n",
            "[CV 1/3; 572/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 572/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.559) total time= 1.8min\n",
            "[CV 2/3; 572/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 572/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.567) total time= 1.8min\n",
            "[CV 3/3; 572/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 572/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.553) total time= 1.6min\n",
            "[CV 1/3; 573/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 573/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.894, test=0.603) total time=  12.8s\n",
            "[CV 2/3; 573/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 573/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.895, test=0.594) total time=  13.0s\n",
            "[CV 3/3; 573/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 573/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=True;, score=(train=0.879, test=0.591) total time=  12.6s\n",
            "[CV 1/3; 574/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 574/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.894, test=0.603) total time=  12.6s\n",
            "[CV 2/3; 574/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 574/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.895, test=0.594) total time=  12.9s\n",
            "[CV 3/3; 574/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 574/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=lbfgs, warm_start=False;, score=(train=0.879, test=0.591) total time=  13.0s\n",
            "[CV 1/3; 575/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 575/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 2/3; 575/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 575/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 575/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 575/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 576/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 576/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 576/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 576/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 3/3; 576/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 576/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.1s\n",
            "[CV 1/3; 577/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 577/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.923, test=0.605) total time=  30.6s\n",
            "[CV 2/3; 577/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 577/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.917, test=0.613) total time=  30.5s\n",
            "[CV 3/3; 577/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 577/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=True;, score=(train=0.909, test=0.604) total time=  30.3s\n",
            "[CV 1/3; 578/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 578/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.923, test=0.605) total time=  30.5s\n",
            "[CV 2/3; 578/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 578/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.917, test=0.613) total time=  29.6s\n",
            "[CV 3/3; 578/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 578/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=sag, warm_start=False;, score=(train=0.909, test=0.604) total time=  29.7s\n",
            "[CV 1/3; 579/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 579/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.882, test=0.624) total time=  39.1s\n",
            "[CV 2/3; 579/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 579/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.877, test=0.625) total time=  39.9s\n",
            "[CV 3/3; 579/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 579/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time=  39.2s\n",
            "[CV 1/3; 580/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 580/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.882, test=0.624) total time=  39.0s\n",
            "[CV 2/3; 580/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 580/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.877, test=0.625) total time=  38.9s\n",
            "[CV 3/3; 580/600] START C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 580/600] END C=200.0, multi_class=multinomial, penalty=l2, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time=  39.5s\n",
            "[CV 1/3; 581/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 1/3; 581/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 581/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 2/3; 581/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 581/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True\n",
            "[CV 3/3; 581/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 582/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 1/3; 582/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 582/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 2/3; 582/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 582/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False\n",
            "[CV 3/3; 582/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=newton-cg, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 583/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 1/3; 583/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 583/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 2/3; 583/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 583/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True\n",
            "[CV 3/3; 583/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 584/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 1/3; 584/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 584/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 2/3; 584/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 584/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False\n",
            "[CV 3/3; 584/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=lbfgs, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 585/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 585/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 585/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 585/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 585/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 585/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 586/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 586/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 586/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 586/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 586/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 586/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 587/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 1/3; 587/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 587/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 2/3; 587/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 587/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True\n",
            "[CV 3/3; 587/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 588/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 1/3; 588/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 588/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 2/3; 588/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 588/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False\n",
            "[CV 3/3; 588/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=sag, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 589/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 1/3; 589/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 589/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 2/3; 589/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 589/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True\n",
            "[CV 3/3; 589/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 590/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 1/3; 590/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 590/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 2/3; 590/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 590/600] START C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False\n",
            "[CV 3/3; 590/600] END C=200.0, multi_class=multinomial, penalty=elasticnet, solver=saga, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 591/600] START C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 591/600] END C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.564) total time= 1.4min\n",
            "[CV 2/3; 591/600] START C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 591/600] END C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.566) total time= 1.3min\n",
            "[CV 3/3; 591/600] START C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 591/600] END C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=True;, score=(train=1.000, test=0.548) total time= 1.4min\n",
            "[CV 1/3; 592/600] START C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 592/600] END C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.564) total time= 1.6min\n",
            "[CV 2/3; 592/600] START C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 592/600] END C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.566) total time= 1.3min\n",
            "[CV 3/3; 592/600] START C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 592/600] END C=200.0, multi_class=multinomial, penalty=none, solver=newton-cg, warm_start=False;, score=(train=1.000, test=0.548) total time= 1.3min\n",
            "[CV 1/3; 593/600] START C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 593/600] END C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.899, test=0.600) total time=  12.2s\n",
            "[CV 2/3; 593/600] START C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 593/600] END C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.888, test=0.592) total time=  12.4s\n",
            "[CV 3/3; 593/600] START C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 593/600] END C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=True;, score=(train=0.880, test=0.585) total time=  12.6s\n",
            "[CV 1/3; 594/600] START C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 594/600] END C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.899, test=0.600) total time=  13.0s\n",
            "[CV 2/3; 594/600] START C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 594/600] END C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.888, test=0.592) total time=  13.0s\n",
            "[CV 3/3; 594/600] START C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 594/600] END C=200.0, multi_class=multinomial, penalty=none, solver=lbfgs, warm_start=False;, score=(train=0.880, test=0.585) total time=  12.8s\n",
            "[CV 1/3; 595/600] START C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 1/3; 595/600] END C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 595/600] START C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 2/3; 595/600] END C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 595/600] START C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True\n",
            "[CV 3/3; 595/600] END C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=True;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 596/600] START C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 1/3; 596/600] END C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 2/3; 596/600] START C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 2/3; 596/600] END C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 3/3; 596/600] START C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False\n",
            "[CV 3/3; 596/600] END C=200.0, multi_class=multinomial, penalty=none, solver=liblinear, warm_start=False;, score=(train=nan, test=nan) total time=   0.0s\n",
            "[CV 1/3; 597/600] START C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 597/600] END C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.923, test=0.605) total time=  29.9s\n",
            "[CV 2/3; 597/600] START C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 597/600] END C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.917, test=0.613) total time=  29.5s\n",
            "[CV 3/3; 597/600] START C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 597/600] END C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=True;, score=(train=0.909, test=0.604) total time=  30.2s\n",
            "[CV 1/3; 598/600] START C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 598/600] END C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.923, test=0.605) total time=  29.5s\n",
            "[CV 2/3; 598/600] START C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 598/600] END C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.917, test=0.613) total time=  30.2s\n",
            "[CV 3/3; 598/600] START C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 598/600] END C=200.0, multi_class=multinomial, penalty=none, solver=sag, warm_start=False;, score=(train=0.909, test=0.604) total time=  30.5s\n",
            "[CV 1/3; 599/600] START C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 599/600] END C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.882, test=0.624) total time=  39.2s\n",
            "[CV 2/3; 599/600] START C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 599/600] END C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.877, test=0.625) total time=  38.9s\n",
            "[CV 3/3; 599/600] START C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 599/600] END C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=True;, score=(train=0.867, test=0.622) total time=  38.7s\n",
            "[CV 1/3; 600/600] START C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/3; 600/600] END C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.882, test=0.624) total time=  39.7s\n",
            "[CV 2/3; 600/600] START C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/3; 600/600] END C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.877, test=0.625) total time=  43.4s\n",
            "[CV 3/3; 600/600] START C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "870 fits failed out of a total of 1800.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 459, in _check_solver\n",
            "    solver\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1473, in fit\n",
            "    % self.l1_ratio\n",
            "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "90 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "60 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1519, in fit\n",
            "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 483, in _check_multi_class\n",
            "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
            "ValueError: Solver liblinear does not support a multinomial backend.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.57657201 0.57657201\n",
            "        nan        nan 0.64587559 0.64587559 0.57369844 0.57369844\n",
            " 0.60125085 0.60125085 0.57302231 0.57302231 0.62440838 0.62440838\n",
            " 0.6362407  0.6362407         nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.55882353 0.55882353 0.59871535 0.59871535        nan        nan\n",
            " 0.62288709 0.62288709 0.63607167 0.63607167        nan        nan\n",
            "        nan        nan 0.57657201 0.57657201        nan        nan\n",
            " 0.64587559 0.64587559 0.57369844 0.57369844 0.60125085 0.60125085\n",
            " 0.57302231 0.57302231 0.62440838 0.62440838 0.6362407  0.6362407\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.55882353 0.55882353\n",
            " 0.59871535 0.59871535        nan        nan 0.62288709 0.62288709\n",
            " 0.63607167 0.63607167        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.63488844 0.63488844\n",
            " 0.56845842 0.56845842 0.59043272 0.59043272        nan        nan\n",
            " 0.60835024 0.60835024 0.62390128 0.62390128        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.55933063 0.55933063 0.59229209 0.59229209\n",
            "        nan        nan 0.6076741  0.6076741  0.62356322 0.62356322\n",
            "        nan        nan        nan        nan 0.56068289 0.56068289\n",
            "        nan        nan 0.63708587 0.63708587 0.56237323 0.56237323\n",
            " 0.59550372 0.59550372 0.56271129 0.56271129 0.62305612 0.62305612\n",
            " 0.63607167 0.63607167        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.55882353 0.55882353 0.59871535 0.59871535        nan        nan\n",
            " 0.62288709 0.62288709 0.63607167 0.63607167        nan        nan\n",
            "        nan        nan 0.56068289 0.56068289        nan        nan\n",
            " 0.63708587 0.63708587 0.56237323 0.56237323 0.59550372 0.59550372\n",
            " 0.56271129 0.56271129 0.62305612 0.62305612 0.63607167 0.63607167\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.55882353 0.55882353\n",
            " 0.59871535 0.59871535        nan        nan 0.62288709 0.62288709\n",
            " 0.63607167 0.63607167        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.62559162 0.62559162\n",
            " 0.56254226 0.56254226 0.59195402 0.59195402        nan        nan\n",
            " 0.6076741  0.6076741  0.62356322 0.62356322        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.55933063 0.55933063 0.59229209 0.59229209\n",
            "        nan        nan 0.6076741  0.6076741  0.62356322 0.62356322\n",
            "        nan        nan        nan        nan 0.56203516 0.56203516\n",
            "        nan        nan 0.63607167 0.63607167 0.56118999 0.56118999\n",
            " 0.59448952 0.59448952 0.56152806 0.56152806 0.62288709 0.62288709\n",
            " 0.6362407  0.6362407         nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.55882353 0.55882353 0.59871535 0.59871535        nan        nan\n",
            " 0.62288709 0.62288709 0.63607167 0.63607167        nan        nan\n",
            "        nan        nan 0.56203516 0.56203516        nan        nan\n",
            " 0.63607167 0.63607167 0.56118999 0.56118999 0.59448952 0.59448952\n",
            " 0.56152806 0.56152806 0.62288709 0.62288709 0.6362407  0.6362407\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.55882353 0.55882353\n",
            " 0.59871535 0.59871535        nan        nan 0.62288709 0.62288709\n",
            " 0.63607167 0.63607167        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.62407032 0.62407032\n",
            " 0.56051386 0.56051386 0.59533469 0.59533469        nan        nan\n",
            " 0.6076741  0.6076741  0.62356322 0.62356322        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.55933063 0.55933063 0.59229209 0.59229209\n",
            "        nan        nan 0.6076741  0.6076741  0.62356322 0.62356322\n",
            "        nan        nan        nan        nan 0.56152806 0.56152806\n",
            "        nan        nan 0.63590264 0.63590264 0.56051386 0.56051386\n",
            " 0.60412441 0.60412441 0.56068289 0.56068289 0.62288709 0.62288709\n",
            " 0.6362407  0.6362407         nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.55882353 0.55882353 0.59871535 0.59871535        nan        nan\n",
            " 0.62288709 0.62288709 0.63607167 0.63607167        nan        nan\n",
            "        nan        nan 0.56152806 0.56152806        nan        nan\n",
            " 0.63590264 0.63590264 0.56051386 0.56051386 0.60412441 0.60412441\n",
            " 0.56068289 0.56068289 0.62288709 0.62288709 0.6362407  0.6362407\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.55882353 0.55882353\n",
            " 0.59871535 0.59871535        nan        nan 0.62288709 0.62288709\n",
            " 0.63607167 0.63607167        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.62356322 0.62356322\n",
            " 0.56017579 0.56017579 0.59161596 0.59161596        nan        nan\n",
            " 0.6076741  0.6076741  0.62356322 0.62356322        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.55933063 0.55933063 0.59229209 0.59229209\n",
            "        nan        nan 0.6076741  0.6076741  0.62356322 0.62356322\n",
            "        nan        nan        nan        nan 0.55983773 0.55983773\n",
            "        nan        nan 0.63607167 0.63607167 0.56017579 0.56017579\n",
            " 0.60226504 0.60226504 0.56051386 0.56051386 0.62288709 0.62288709\n",
            " 0.6362407  0.6362407         nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.55882353 0.55882353 0.59871535 0.59871535        nan        nan\n",
            " 0.62288709 0.62288709 0.63607167 0.63607167        nan        nan\n",
            "        nan        nan 0.55983773 0.55983773        nan        nan\n",
            " 0.63607167 0.63607167 0.56017579 0.56017579 0.60226504 0.60226504\n",
            " 0.56051386 0.56051386 0.62288709 0.62288709 0.6362407  0.6362407\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.55882353 0.55882353\n",
            " 0.59871535 0.59871535        nan        nan 0.62288709 0.62288709\n",
            " 0.63607167 0.63607167        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.62356322 0.62356322\n",
            " 0.5596687  0.5596687  0.59617985 0.59617985        nan        nan\n",
            " 0.6076741  0.6076741  0.62356322 0.62356322        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 0.55933063 0.55933063 0.59229209 0.59229209\n",
            "        nan        nan 0.6076741  0.6076741  0.62356322 0.62356322]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan        nan 0.9754902  0.9754902\n",
            "        nan        nan 0.81752874 0.81752874 0.99678837 0.99678837\n",
            " 0.8744929  0.8744929  0.99678837 0.99678837 0.87390128 0.87390128\n",
            " 0.83823529 0.83823529        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         0.87068966 0.87068966        nan        nan\n",
            " 0.875      0.875      0.83899594 0.83899594        nan        nan\n",
            "        nan        nan 0.9754902  0.9754902         nan        nan\n",
            " 0.81752874 0.81752874 0.99678837 0.99678837 0.8744929  0.8744929\n",
            " 0.99678837 0.99678837 0.87390128 0.87390128 0.83823529 0.83823529\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 1.         1.\n",
            " 0.87068966 0.87068966        nan        nan 0.875      0.875\n",
            " 0.83899594 0.83899594        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.85353279 0.85353279\n",
            " 0.99966193 0.99966193 0.89097363 0.89097363        nan        nan\n",
            " 0.91514537 0.91514537 0.87457742 0.87457742        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 1.         1.         0.88911427 0.88911427\n",
            "        nan        nan 0.91624408 0.91624408 0.87516903 0.87516903\n",
            "        nan        nan        nan        nan 1.         1.\n",
            "        nan        nan 0.83637593 0.83637593 1.         1.\n",
            " 0.87432387 0.87432387 1.         1.         0.87466193 0.87466193\n",
            " 0.83891143 0.83891143        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         0.87068966 0.87068966        nan        nan\n",
            " 0.875      0.875      0.83899594 0.83899594        nan        nan\n",
            "        nan        nan 1.         1.                nan        nan\n",
            " 0.83637593 0.83637593 1.         1.         0.87432387 0.87432387\n",
            " 1.         1.         0.87466193 0.87466193 0.83891143 0.83891143\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 1.         1.\n",
            " 0.87068966 0.87068966        nan        nan 0.875      0.875\n",
            " 0.83899594 0.83899594        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.87254902 0.87254902\n",
            " 1.         1.         0.88902975 0.88902975        nan        nan\n",
            " 0.91615957 0.91615957 0.87516903 0.87516903        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 1.         1.         0.88911427 0.88911427\n",
            "        nan        nan 0.91624408 0.91624408 0.87516903 0.87516903\n",
            "        nan        nan        nan        nan 1.         1.\n",
            "        nan        nan 0.83840433 0.83840433 1.         1.\n",
            " 0.88615619 0.88615619 1.         1.         0.875      0.875\n",
            " 0.83899594 0.83899594        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         0.87068966 0.87068966        nan        nan\n",
            " 0.875      0.875      0.83899594 0.83899594        nan        nan\n",
            "        nan        nan 1.         1.                nan        nan\n",
            " 0.83840433 0.83840433 1.         1.         0.88615619 0.88615619\n",
            " 1.         1.         0.875      0.875      0.83899594 0.83899594\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 1.         1.\n",
            " 0.87068966 0.87068966        nan        nan 0.875      0.875\n",
            " 0.83899594 0.83899594        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.8744929  0.8744929\n",
            " 1.         1.         0.887762   0.887762          nan        nan\n",
            " 0.91624408 0.91624408 0.87516903 0.87516903        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 1.         1.         0.88911427 0.88911427\n",
            "        nan        nan 0.91624408 0.91624408 0.87516903 0.87516903\n",
            "        nan        nan        nan        nan 1.         1.\n",
            "        nan        nan 0.83874239 0.83874239 1.         1.\n",
            " 0.86671738 0.86671738 1.         1.         0.875      0.875\n",
            " 0.83899594 0.83899594        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         0.87068966 0.87068966        nan        nan\n",
            " 0.875      0.875      0.83899594 0.83899594        nan        nan\n",
            "        nan        nan 1.         1.                nan        nan\n",
            " 0.83874239 0.83874239 1.         1.         0.86671738 0.86671738\n",
            " 1.         1.         0.875      0.875      0.83899594 0.83899594\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 1.         1.\n",
            " 0.87068966 0.87068966        nan        nan 0.875      0.875\n",
            " 0.83899594 0.83899594        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.87474645 0.87474645\n",
            " 1.         1.         0.8918188  0.8918188         nan        nan\n",
            " 0.91624408 0.91624408 0.87516903 0.87516903        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 1.         1.         0.88911427 0.88911427\n",
            "        nan        nan 0.91624408 0.91624408 0.87516903 0.87516903\n",
            "        nan        nan        nan        nan 1.         1.\n",
            "        nan        nan 0.83891143 0.83891143 1.         1.\n",
            " 0.86663286 0.86663286 1.         1.         0.875      0.875\n",
            " 0.83899594 0.83899594        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         0.87068966 0.87068966        nan        nan\n",
            " 0.875      0.875      0.83899594 0.83899594        nan        nan\n",
            "        nan        nan 1.         1.                nan        nan\n",
            " 0.83891143 0.83891143 1.         1.         0.86663286 0.86663286\n",
            " 1.         1.         0.875      0.875      0.83899594 0.83899594\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 1.         1.\n",
            " 0.87068966 0.87068966        nan        nan 0.875      0.875\n",
            " 0.83899594 0.83899594        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan 0.875      0.875\n",
            " 1.         1.         0.88902975 0.88902975        nan        nan\n",
            " 0.91624408 0.91624408 0.87516903 0.87516903        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan 1.         1.         0.88911427 0.88911427\n",
            "        nan        nan 0.91624408 0.91624408 0.87516903 0.87516903]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/3; 600/600] END C=200.0, multi_class=multinomial, penalty=none, solver=saga, warm_start=False;, score=(train=0.867, test=0.622) total time=  39.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=LogisticRegression(C=1.5, penalty='l1', random_state=42,\n",
              "                                          solver='saga'),\n",
              "             param_grid=[{'C': [1.5, 10.0, 50.0, 100.0, 200.0],\n",
              "                          'multi_class': ['auto', 'ovr', 'multinomial'],\n",
              "                          'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
              "                          'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
              "                                     'saga'],\n",
              "                          'warm_start': [True, False]}],\n",
              "             return_train_score=True, scoring='accuracy', verbose=10)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search.fit(x_train , y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-8ANodsX3Cw",
        "outputId": "5b4b02fe-10d1-464a-a602-06e002215ddd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.5, penalty='l1', random_state=42, solver='saga',\n",
              "                   warm_start=True)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_model = grid_search.best_estimator_\n",
        "final_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFmK1pqvYlLV"
      },
      "outputs": [],
      "source": [
        "y_predict = final_model.predict(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54U7ifM_Y_Hs",
        "outputId": "396f6b20-0d33-4949-c0d5-f6c4872a4f40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.84      0.75       975\n",
            "           1       0.44      0.25      0.32       504\n",
            "\n",
            "    accuracy                           0.64      1479\n",
            "   macro avg       0.56      0.54      0.53      1479\n",
            "weighted avg       0.60      0.64      0.60      1479\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test,y_predict))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}